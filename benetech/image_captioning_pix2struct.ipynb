{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSWkkqiKqrhv"
   },
   "source": [
    "## Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.29.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jaKvVdQ0u2Ri"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import  glob\n",
    "import json\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j-D24wAMu7yx"
   },
   "outputs": [],
   "source": [
    "image_path = glob('./train/images/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cA9qlGKG1_Jm"
   },
   "outputs": [],
   "source": [
    "label_path = glob('./train/annotations/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j4osCST92Gr8"
   },
   "outputs": [],
   "source": [
    "assert len(image_path) == 60578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "eXcFVLQS2IVN",
    "outputId": "9b0733b3-6eae-406c-f8b9-cdf4237a8937"
   },
   "outputs": [],
   "source": [
    "assert len(label_path)== 60578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLJ1yB6gyhk9"
   },
   "source": [
    "### Understanding `max_patches` argument\n",
    "\n",
    "The paper introduces a new paradigm for processing the input image. It takes the image and create `n_patches` aspect-ratio preserving patches, and concatenates the remaining sequence with padding tokens to finally get `max_patches` patches. It appears that this argument is quite crucial for training and evaluation, as the model becomes very sensitive to this parameter.\n",
    "\n",
    "For the sake of our example, we will fine-tune a model with `max_patches=1024`.\n",
    "\n",
    "Note that most of the `-base` models have been fine-tuned with `max_patches=2048`, and `4096` for `-large` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T17:41:55.251013Z",
     "start_time": "2023-05-17T17:41:52.322238Z"
    },
    "id": "93od71o_qq_V"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "MAX_PATCHES = 2048\n",
    "\n",
    "class ImageCaptioningDataset(Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.dataset = df\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.iloc[idx, :]\n",
    "        image = Image.open(row.image_path)\n",
    "        #display(image)\n",
    "        encoding = self.processor(images=image,\n",
    "                                  #prompt\n",
    "                                  #文本检测 去检测x y轴的label x-axis<X,X,X,X,> Y-axis<y,y,y,y>\n",
    "                                  # DBnet\n",
    "                                  text=\"Generate underlying data table of the figure below:\",\n",
    "                                  font_path=\"arial.ttf\",\n",
    "                                  return_tensors=\"pt\",\n",
    "                                  add_special_tokens=True, max_patches=MAX_PATCHES)\n",
    "        \n",
    "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
    "        encoding[\"text\"] = row.label \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX6Nv8aEm0yk",
    "tags": []
   },
   "source": [
    "## Load model and processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T17:42:28.469909Z",
     "start_time": "2023-05-17T17:41:54.954281Z"
    },
    "id": "hLhbdBLNxBuF"
   },
   "outputs": [],
   "source": [
    "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration\n",
    "\n",
    "processor = Pix2StructProcessor.from_pretrained(\"google/matcha-base\")\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained(\"google/matcha-plotqa-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXlkVag6nDx3"
   },
   "source": [
    "Now that we have loaded the processor, let's load the dataset and the dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T17:42:28.476909Z",
     "start_time": "2023-05-17T17:42:28.459197Z"
    },
    "id": "-nhDbOCmESlB"
   },
   "outputs": [],
   "source": [
    "def collator(batch):\n",
    "    new_batch = {\"flattened_patches\": [], \"attention_mask\": []}\n",
    "    texts = [item[\"text\"] for item in batch]\n",
    "    # print(texts)\n",
    "    text_inputs = processor.tokenizer(text=texts,\n",
    "                                      padding=\"max_length\",\n",
    "                                      return_tensors=\"pt\",\n",
    "                                      add_special_tokens=True,\n",
    "                                      max_length=512,\n",
    "                                      truncation=True\n",
    "                                      )\n",
    "\n",
    "    new_batch[\"labels\"] = text_inputs.input_ids\n",
    "\n",
    "    for item in batch:\n",
    "        new_batch[\"flattened_patches\"].append(item[\"flattened_patches\"])\n",
    "        new_batch[\"attention_mask\"].append(item[\"attention_mask\"])\n",
    "\n",
    "    new_batch[\"flattened_patches\"] = torch.stack(new_batch[\"flattened_patches\"])\n",
    "    new_batch[\"attention_mask\"] = torch.stack(new_batch[\"attention_mask\"])\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T17:42:29.234252Z",
     "start_time": "2023-05-17T17:42:28.472909Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQeZLvfs8paE",
    "outputId": "77121cd8-cedf-499f-fb35-e7413d2e51c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60578\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train_with_fold.csv')\n",
    "print(len(df))\n",
    "train_df = df[df['fold'] != 0]\n",
    "train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    scheduler = 'cosine'  # ['linear', 'cosine']\n",
    "    batch_scheduler = True\n",
    "    num_cycles = 0.5  # 1.5\n",
    "    num_warmup_steps = 0.2\n",
    "    max_input_length = 130\n",
    "    epochs = 10  # 5\n",
    "    encoder_lr = 10e-6\n",
    "    decoder_lr = 10e-6\n",
    "    min_lr = 0.5e-6\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    weight_decay = 0\n",
    "    num_fold = 5\n",
    "    batch_size = 2\n",
    "    seed = 1006\n",
    "    num_workers = 2\n",
    "    device='cuda:1'\n",
    "    print_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T17:42:29.248252Z",
     "start_time": "2023-05-17T17:42:29.230483Z"
    },
    "id": "hxajSwc3w-LU"
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageCaptioningDataset(train_df, processor)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=CFG.batch_size, collate_fn=collator, pin_memory=True,\n",
    "                                  prefetch_factor=40, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "    cfg.num_warmup_steps = cfg.num_warmup_steps * num_train_steps\n",
    "    if cfg.scheduler == 'linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "        )\n",
    "    elif cfg.scheduler == 'cosine':\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps,\n",
    "            num_cycles=cfg.num_cycles\n",
    "        )\n",
    "    return scheduler\n",
    "\n",
    "num_train_steps = int(len(train_dataset) / CFG.batch_size * CFG.epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_CyLSgBxyL2"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cVsJdd2nV1S"
   },
   "source": [
    "Let's train the model! Run the simply the cell below for training the model. We have observed that finding the best hyper-parameters was quite challenging and required a lot of trials and errors, as the model can easily enter in \"collapse-model\" (always predicting the same output, no matter the input) if the HP are not chosen correctly. In this example, we found out that using `AdamW` optimizer with `lr=1e-5` seemed to be the best approach.\n",
    "\n",
    "Let's also print the generation output of the model each 10 epochs!\n",
    "\n",
    "Bear in mind that the model took some time to converge, for instance to get decent results we had to let the script run for ~1hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pix2StructForConditionalGeneration(\n",
       "  (encoder): Pix2StructVisionModel(\n",
       "    (embeddings): Pix2StructVisionEmbeddings(\n",
       "      (patch_projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (row_embedder): Embedding(4096, 768)\n",
       "      (column_embedder): Embedding(4096, 768)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Pix2StructVisionEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (1): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (2): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (3): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (4): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (5): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (6): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (7): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (8): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (9): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (10): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "        (11): Pix2StructVisionLayer(\n",
       "          (attention): Pix2StructVisionAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (mlp): Pix2StructVisionMlp(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (pre_mlp_layer_norm): Pix2StructLayerNorm()\n",
       "          (pre_attention_layer_norm): Pix2StructLayerNorm()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): Pix2StructLayerNorm()\n",
       "  )\n",
       "  (decoder): Pix2StructTextModel(\n",
       "    (embed_tokens): Embedding(50244, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (relative_attention_bias): Embedding(32, 12)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Pix2StructTextBlock(\n",
       "        (self_attention): Pix2StructTextLayerSelfAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_decoder_attention): Pix2StructTextLayerCrossAttention(\n",
       "          (attention): Pix2StructTextAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (output): Linear(in_features=768, out_features=768, bias=False)\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mlp): Pix2StructTextLayerFF(\n",
       "          (DenseReluDense): Pix2StructTextDenseGatedActDense(\n",
       "            (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "            (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (act): NewGELUActivation()\n",
       "          )\n",
       "          (layer_norm): Pix2StructLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): Pix2StructLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (lm_head): Linear(in_features=768, out_features=50244, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model.to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "023b5038cdf34f7f96f295311001d78d",
      "472f6d8ee41443a0a82993c72ae6fe40",
      "f342d35498a345f1991a5afc0a0edbca",
      "9565dc8405bb4a5fb2850fc1e12fdd92",
      "5e1878670f1f446085b14a37e9072a95",
      "7a6f464a1ffa4cc49b634da46809e681",
      "e203a6f9f2c1430582f060a9ea71c57e",
      "f6721fa7ba8742129ad53abffb5a4d2b",
      "b26d75d84741429fa34441fec197307f",
      "b6ff9c8e096b4cb48c239610131b8bb7",
      "ca383499f23640b38d7e8701d3daea32",
      "47c8e38fe9d24f6b824acf7e4f1c3ce6",
      "dbbc074448f740f99b37e456752a67e6",
      "e4c9e1a41cbc4b86a249fee581c9175e",
      "4f3f0a98f5834f0d85b11265e9b795e4",
      "5a8622ee44f54015b58155a6a8a6cbcd",
      "2829b790c46d4e05983d501f910ed7f7",
      "28ba10dfff154193a8bfb648e7fca4c3",
      "d158c3785b5c4b13a9024a0d3e1c0ef2",
      "dd3e462a7cee40f9b6b6a63307c0735b",
      "d7f912192edf4cdcbdd8154b712faf84",
      "2a91ec7117534897ab30f096de821816",
      "d86afaa5675a4776846ffaf4c97e409a",
      "2cab1d494c454a1abfca420484d952f6",
      "9aca2f8e1f6644eebddb205ea4a5e0c5",
      "987333f84cdb4dfca94e41e1b6b2246e",
      "309537918947492d8c771b8b20aef21e",
      "7177fa27755e4249a12444cc885c7abe",
      "cf6e28052907414ab3f98c1f45672d29",
      "a62f1a1670b34720a640c221f1b8d0f1",
      "ba63637b809d43aa809cb8c81c8a9d65",
      "f21445de34624b6e92a86a4fc470c71f",
      "1c162151952d4b04a764ed1999e6c46b"
     ]
    },
    "id": "6cCVhsmJxxjH",
    "outputId": "6a1cd0fd-7cca-426a-8c20-794cfcb5f868",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a913cfdcd01f4e7bae4f3f0f243be46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6629443764686584 lr : 0.000010 \n",
      "Loss: 0.7359920144081116 lr : 0.000010 \n",
      "Loss: 1.233712911605835 lr : 0.000010 \n",
      "Loss: 1.0288405418395996 lr : 0.000010 \n",
      "Loss: 0.858933687210083 lr : 0.000010 \n",
      "Loss: 1.2682100534439087 lr : 0.000010 \n",
      "Loss: 0.7170652747154236 lr : 0.000010 \n",
      "Loss: 0.6052768230438232 lr : 0.000010 \n",
      "Loss: 0.481381893157959 lr : 0.000010 \n",
      "Loss: 0.5676138401031494 lr : 0.000010 \n",
      "Loss: 1.1902427673339844 lr : 0.000010 \n",
      "Loss: 0.6400188207626343 lr : 0.000010 \n",
      "Loss: 0.745026171207428 lr : 0.000010 \n",
      "Loss: 1.1922599077224731 lr : 0.000010 \n",
      "Loss: 0.5645087361335754 lr : 0.000010 \n",
      "Loss: 0.31349435448646545 lr : 0.000010 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0860344171524048 lr : 0.000010 \n",
      "Loss: 0.7062138319015503 lr : 0.000010 \n",
      "Loss: 0.8567994832992554 lr : 0.000010 \n",
      "Loss: 0.8080344200134277 lr : 0.000010 \n",
      "Loss: 0.82718825340271 lr : 0.000010 \n",
      "Loss: 0.40620002150535583 lr : 0.000010 \n",
      "Loss: 0.68768310546875 lr : 0.000010 \n",
      "Loss: 0.650678277015686 lr : 0.000010 \n",
      "Loss: 0.7405890822410583 lr : 0.000010 \n",
      "Loss: 1.1742229461669922 lr : 0.000010 \n",
      "Loss: 0.9242892265319824 lr : 0.000010 \n",
      "Loss: 1.201245665550232 lr : 0.000010 \n",
      "Loss: 1.696030855178833 lr : 0.000010 \n",
      "Loss: 0.9377285242080688 lr : 0.000010 \n",
      "Loss: 0.912734866142273 lr : 0.000010 \n",
      "Loss: 0.6134945750236511 lr : 0.000010 \n",
      "Loss: 0.7733114957809448 lr : 0.000010 \n",
      "Loss: 1.234897255897522 lr : 0.000010 \n",
      "Loss: 0.94827800989151 lr : 0.000010 \n",
      "Loss: 1.061649203300476 lr : 0.000010 \n",
      "Loss: 0.836963951587677 lr : 0.000010 \n",
      "Loss: 1.1883182525634766 lr : 0.000010 \n",
      "Loss: 0.46650922298431396 lr : 0.000010 \n",
      "Loss: 1.118831753730774 lr : 0.000010 \n",
      "Loss: 0.8363049030303955 lr : 0.000010 \n",
      "Loss: 0.910411536693573 lr : 0.000010 \n",
      "Loss: 1.0111016035079956 lr : 0.000010 \n",
      "Loss: 0.5972487926483154 lr : 0.000010 \n",
      "Loss: 0.10384853929281235 lr : 0.000010 \n",
      "Loss: 1.1294745206832886 lr : 0.000010 \n",
      "Loss: 0.7236688137054443 lr : 0.000010 \n",
      "Loss: 1.231167197227478 lr : 0.000010 \n",
      "Loss: 0.4603332281112671 lr : 0.000010 \n",
      "Loss: 1.1743762493133545 lr : 0.000010 \n",
      "Loss: 0.9918007850646973 lr : 0.000010 \n",
      "Loss: 0.6706739068031311 lr : 0.000010 \n",
      "Loss: 0.39522993564605713 lr : 0.000010 \n",
      "Loss: 0.5674440860748291 lr : 0.000010 \n",
      "Loss: 0.578926682472229 lr : 0.000010 \n",
      "Loss: 1.028795838356018 lr : 0.000010 \n",
      "Loss: 1.1123653650283813 lr : 0.000010 \n",
      "Loss: 1.033033847808838 lr : 0.000010 \n",
      "Loss: 0.8119148015975952 lr : 0.000010 \n",
      "Loss: 0.9595364332199097 lr : 0.000010 \n",
      "Loss: 1.1122580766677856 lr : 0.000010 \n",
      "Loss: 0.5044004917144775 lr : 0.000010 \n",
      "Loss: 1.1371451616287231 lr : 0.000010 \n",
      "Loss: 0.7477231621742249 lr : 0.000010 \n",
      "Loss: 0.797336220741272 lr : 0.000010 \n",
      "Loss: 1.1244862079620361 lr : 0.000010 \n",
      "Loss: 1.1313199996948242 lr : 0.000010 \n",
      "Loss: 0.5525172352790833 lr : 0.000010 \n",
      "Loss: 0.8330197930335999 lr : 0.000010 \n",
      "Loss: 0.6889067888259888 lr : 0.000010 \n",
      "Loss: 0.7656282186508179 lr : 0.000010 \n",
      "Loss: 0.5986798405647278 lr : 0.000010 \n",
      "Loss: 0.8906092643737793 lr : 0.000010 \n",
      "Loss: 1.0753413438796997 lr : 0.000010 \n",
      "Loss: 1.2030142545700073 lr : 0.000010 \n",
      "Loss: 0.003926523961126804 lr : 0.000010 \n",
      "Loss: 0.5330255031585693 lr : 0.000010 \n",
      "Loss: 0.7291730642318726 lr : 0.000010 \n",
      "Loss: 0.2830817997455597 lr : 0.000010 \n",
      "Loss: 0.3462681770324707 lr : 0.000010 \n",
      "Loss: 0.5274521708488464 lr : 0.000010 \n",
      "Loss: 0.6059457063674927 lr : 0.000010 \n",
      "Loss: 1.3024108409881592 lr : 0.000010 \n",
      "Loss: 0.7662146687507629 lr : 0.000010 \n",
      "Loss: 0.8517789244651794 lr : 0.000010 \n",
      "Loss: 1.3792622089385986 lr : 0.000010 \n",
      "Loss: 0.532585859298706 lr : 0.000010 \n",
      "Loss: 0.660832941532135 lr : 0.000010 \n",
      "Loss: 0.3327152729034424 lr : 0.000010 \n",
      "Loss: 0.9488958120346069 lr : 0.000010 \n",
      "Loss: 1.1151621341705322 lr : 0.000010 \n",
      "Loss: 0.7142887115478516 lr : 0.000010 \n",
      "Loss: 0.8987767696380615 lr : 0.000010 \n",
      "Loss: 1.0607701539993286 lr : 0.000010 \n",
      "Loss: 0.7885156869888306 lr : 0.000010 \n",
      "Loss: 0.7270262837409973 lr : 0.000010 \n",
      "Loss: 0.6189553737640381 lr : 0.000010 \n",
      "Loss: 0.6997007131576538 lr : 0.000010 \n",
      "Loss: 0.3426240086555481 lr : 0.000010 \n",
      "Loss: 1.2907633781433105 lr : 0.000010 \n",
      "Loss: 0.48909449577331543 lr : 0.000010 \n",
      "Loss: 1.227655053138733 lr : 0.000010 \n",
      "Loss: 0.5827270746231079 lr : 0.000010 \n",
      "Loss: 1.1030583381652832 lr : 0.000010 \n",
      "Loss: 0.6059188842773438 lr : 0.000010 \n",
      "Loss: 0.8530222773551941 lr : 0.000010 \n",
      "Loss: 0.9269464015960693 lr : 0.000010 \n",
      "Loss: 1.2351932525634766 lr : 0.000010 \n",
      "Loss: 1.2336255311965942 lr : 0.000010 \n",
      "Loss: 0.7919781804084778 lr : 0.000010 \n",
      "Loss: 0.3264159560203552 lr : 0.000010 \n",
      "Loss: 1.0247292518615723 lr : 0.000010 \n",
      "Loss: 1.4830292463302612 lr : 0.000010 \n",
      "Loss: 1.1041820049285889 lr : 0.000010 \n",
      "Loss: 0.8431230187416077 lr : 0.000010 \n",
      "Loss: 1.1733486652374268 lr : 0.000010 \n",
      "Loss: 0.6419274806976318 lr : 0.000010 \n",
      "Loss: 0.22614382207393646 lr : 0.000010 \n",
      "Loss: 0.6357713341712952 lr : 0.000010 \n",
      "Loss: 0.8962152600288391 lr : 0.000010 \n",
      "Loss: 1.0654239654541016 lr : 0.000010 \n",
      "Loss: 0.8040656447410583 lr : 0.000010 \n",
      "Loss: 0.5258939862251282 lr : 0.000010 \n",
      "Loss: 0.48414847254753113 lr : 0.000010 \n",
      "Loss: 0.8551028966903687 lr : 0.000010 \n",
      "Loss: 1.0994664430618286 lr : 0.000010 \n",
      "Loss: 0.9191252589225769 lr : 0.000010 \n",
      "Loss: 1.0638107061386108 lr : 0.000010 \n",
      "Loss: 0.6979290843009949 lr : 0.000010 \n",
      "Loss: 1.1890146732330322 lr : 0.000010 \n",
      "Loss: 0.3597036600112915 lr : 0.000010 \n",
      "Loss: 1.1574158668518066 lr : 0.000010 \n",
      "Loss: 0.6086590886116028 lr : 0.000010 \n",
      "Loss: 0.6590339541435242 lr : 0.000010 \n",
      "Loss: 1.0594943761825562 lr : 0.000010 \n",
      "Loss: 0.2694428861141205 lr : 0.000010 \n",
      "Loss: 1.2378473281860352 lr : 0.000010 \n",
      "Loss: 1.0063821077346802 lr : 0.000010 \n",
      "Loss: 1.2075419425964355 lr : 0.000010 \n",
      "Loss: 0.0033652912825345993 lr : 0.000010 \n",
      "Loss: 0.7144282460212708 lr : 0.000010 \n",
      "Loss: 0.8967868685722351 lr : 0.000010 \n",
      "Loss: 0.8198941946029663 lr : 0.000010 \n",
      "Loss: 0.45651009678840637 lr : 0.000010 \n",
      "Loss: 0.17479300498962402 lr : 0.000010 \n",
      "Loss: 1.2127645015716553 lr : 0.000010 \n",
      "Loss: 0.8968836665153503 lr : 0.000010 \n",
      "Loss: 1.19257652759552 lr : 0.000010 \n",
      "Loss: 0.3500654101371765 lr : 0.000010 \n",
      "Loss: 1.2902281284332275 lr : 0.000010 \n",
      "Loss: 1.1222699880599976 lr : 0.000010 \n",
      "Loss: 0.6286781430244446 lr : 0.000010 \n",
      "Loss: 0.8460055589675903 lr : 0.000010 \n",
      "Loss: 0.9485737681388855 lr : 0.000010 \n",
      "Loss: 0.884475827217102 lr : 0.000010 \n",
      "Loss: 0.7623966932296753 lr : 0.000010 \n",
      "Loss: 0.8588679432868958 lr : 0.000010 \n",
      "Loss: 0.8465418219566345 lr : 0.000010 \n",
      "Loss: 1.1130019426345825 lr : 0.000010 \n",
      "Loss: 0.8587322235107422 lr : 0.000010 \n",
      "Loss: 0.8491860032081604 lr : 0.000010 \n",
      "Loss: 0.5539913177490234 lr : 0.000010 \n",
      "Loss: 0.8798778653144836 lr : 0.000010 \n",
      "Loss: 0.9452258348464966 lr : 0.000010 \n",
      "Loss: 0.9745784997940063 lr : 0.000010 \n",
      "Loss: 1.114393949508667 lr : 0.000010 \n",
      "Loss: 0.7187064290046692 lr : 0.000010 \n",
      "Loss: 0.7411434054374695 lr : 0.000010 \n",
      "Loss: 0.6722549796104431 lr : 0.000010 \n",
      "Loss: 0.5036647319793701 lr : 0.000010 \n",
      "Loss: 0.35821783542633057 lr : 0.000010 \n",
      "Loss: 0.44748514890670776 lr : 0.000010 \n",
      "Loss: 0.33289068937301636 lr : 0.000010 \n",
      "Loss: 1.0253403186798096 lr : 0.000010 \n",
      "Loss: 0.6573119163513184 lr : 0.000010 \n",
      "Loss: 0.9183825850486755 lr : 0.000010 \n",
      "Loss: 0.5322446823120117 lr : 0.000010 \n",
      "Loss: 0.2500128149986267 lr : 0.000010 \n",
      "Loss: 0.8819547891616821 lr : 0.000010 \n",
      "Loss: 0.7219669818878174 lr : 0.000010 \n",
      "Loss: 0.8587358593940735 lr : 0.000010 \n",
      "Loss: 0.6086996793746948 lr : 0.000010 \n",
      "Loss: 0.8779739141464233 lr : 0.000010 \n",
      "Loss: 0.3309701383113861 lr : 0.000010 \n",
      "Loss: 1.195095181465149 lr : 0.000010 \n",
      "Loss: 1.6156823635101318 lr : 0.000010 \n",
      "Loss: 0.6276137232780457 lr : 0.000010 \n",
      "Loss: 1.5952262878417969 lr : 0.000010 \n",
      "Loss: 0.7716445326805115 lr : 0.000010 \n",
      "Loss: 0.7638170719146729 lr : 0.000010 \n",
      "Loss: 0.42794445157051086 lr : 0.000010 \n",
      "Loss: 0.21640224754810333 lr : 0.000010 \n",
      "Loss: 0.7783409357070923 lr : 0.000010 \n",
      "Loss: 0.5656964778900146 lr : 0.000010 \n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d1353922244dfc999c6053934a0995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7556231617927551 lr : 0.000010 \n",
      "Loss: 0.03452817723155022 lr : 0.000010 \n",
      "Loss: 1.0818331241607666 lr : 0.000010 \n",
      "Loss: 1.1988829374313354 lr : 0.000010 \n",
      "Loss: 1.0498042106628418 lr : 0.000010 \n",
      "Loss: 0.8261632919311523 lr : 0.000010 \n",
      "Loss: 0.6496695876121521 lr : 0.000010 \n",
      "Loss: 1.0359430313110352 lr : 0.000010 \n",
      "Loss: 0.6875914931297302 lr : 0.000010 \n",
      "Loss: 0.8585395812988281 lr : 0.000010 \n",
      "Loss: 0.7067690491676331 lr : 0.000010 \n",
      "Loss: 0.9208577275276184 lr : 0.000010 \n",
      "Loss: 0.6945407390594482 lr : 0.000010 \n",
      "Loss: 0.7719060182571411 lr : 0.000010 \n",
      "Loss: 0.9553905725479126 lr : 0.000010 \n",
      "Loss: 0.5768434405326843 lr : 0.000010 \n",
      "Loss: 1.2601056098937988 lr : 0.000010 \n",
      "Loss: 1.325897455215454 lr : 0.000010 \n",
      "Loss: 0.303303599357605 lr : 0.000010 \n",
      "Loss: 0.38255560398101807 lr : 0.000010 \n",
      "Loss: 0.8272032737731934 lr : 0.000010 \n",
      "Loss: 0.3749936521053314 lr : 0.000010 \n",
      "Loss: 0.6913418769836426 lr : 0.000010 \n",
      "Loss: 0.6609581708908081 lr : 0.000010 \n",
      "Loss: 0.7606866359710693 lr : 0.000010 \n",
      "Loss: 1.1730802059173584 lr : 0.000010 \n",
      "Loss: 0.7181205153465271 lr : 0.000010 \n",
      "Loss: 0.9052181243896484 lr : 0.000010 \n",
      "Loss: 1.050182819366455 lr : 0.000010 \n",
      "Loss: 0.6139341592788696 lr : 0.000010 \n",
      "Loss: 0.7616227269172668 lr : 0.000010 \n",
      "Loss: 0.8014070987701416 lr : 0.000010 \n",
      "Loss: 0.7876209020614624 lr : 0.000010 \n",
      "Loss: 1.4155734777450562 lr : 0.000010 \n",
      "Loss: 0.6923652291297913 lr : 0.000010 \n",
      "Loss: 0.6351240873336792 lr : 0.000010 \n",
      "Loss: 1.1669527292251587 lr : 0.000009 \n",
      "Loss: 1.0467116832733154 lr : 0.000009 \n",
      "Loss: 0.6582197546958923 lr : 0.000009 \n",
      "Loss: 0.5733306407928467 lr : 0.000009 \n",
      "Loss: 0.46433043479919434 lr : 0.000009 \n",
      "Loss: 0.941097617149353 lr : 0.000009 \n",
      "Loss: 1.1658852100372314 lr : 0.000009 \n",
      "Loss: 1.5596294403076172 lr : 0.000009 \n",
      "Loss: 1.0034061670303345 lr : 0.000009 \n",
      "Loss: 0.6274771094322205 lr : 0.000009 \n",
      "Loss: 0.6336899995803833 lr : 0.000009 \n",
      "Loss: 0.6452932357788086 lr : 0.000009 \n",
      "Loss: 1.0728440284729004 lr : 0.000009 \n",
      "Loss: 0.7557709217071533 lr : 0.000009 \n",
      "Loss: 0.8138638734817505 lr : 0.000009 \n",
      "Loss: 0.8443242311477661 lr : 0.000009 \n",
      "Loss: 1.2104154825210571 lr : 0.000009 \n",
      "Loss: 1.0070542097091675 lr : 0.000009 \n",
      "Loss: 0.6869138479232788 lr : 0.000009 \n",
      "Loss: 0.5909350514411926 lr : 0.000009 \n",
      "Loss: 0.44471117854118347 lr : 0.000009 \n",
      "Loss: 0.5567247271537781 lr : 0.000009 \n",
      "Loss: 0.8658996224403381 lr : 0.000009 \n",
      "Loss: 0.7815889120101929 lr : 0.000009 \n",
      "Loss: 0.6002501845359802 lr : 0.000009 \n",
      "Loss: 0.5432673692703247 lr : 0.000009 \n",
      "Loss: 0.5874218940734863 lr : 0.000009 \n",
      "Loss: 0.606942355632782 lr : 0.000009 \n",
      "Loss: 1.0004898309707642 lr : 0.000009 \n",
      "Loss: 1.3784795999526978 lr : 0.000009 \n",
      "Loss: 1.3666985034942627 lr : 0.000009 \n",
      "Loss: 1.1684335470199585 lr : 0.000009 \n",
      "Loss: 0.8002325296401978 lr : 0.000009 \n",
      "Loss: 0.6246154308319092 lr : 0.000009 \n",
      "Loss: 0.7329290509223938 lr : 0.000009 \n",
      "Loss: 0.6058180928230286 lr : 0.000009 \n",
      "Loss: 6.183946970850229e-05 lr : 0.000009 \n",
      "Loss: 0.6296684741973877 lr : 0.000009 \n",
      "Loss: 1.2896010875701904 lr : 0.000009 \n",
      "Loss: 0.672153115272522 lr : 0.000009 \n",
      "Loss: 0.6710959672927856 lr : 0.000009 \n",
      "Loss: 0.5564078688621521 lr : 0.000009 \n",
      "Loss: 0.8862651586532593 lr : 0.000009 \n",
      "Loss: 0.6240354180335999 lr : 0.000009 \n",
      "Loss: 1.1716892719268799 lr : 0.000009 \n",
      "Loss: 0.8730427622795105 lr : 0.000009 \n",
      "Loss: 0.4674251079559326 lr : 0.000009 \n",
      "Loss: 0.6852100491523743 lr : 0.000009 \n",
      "Loss: 0.7227196097373962 lr : 0.000009 \n",
      "Loss: 0.4383878707885742 lr : 0.000009 \n",
      "Loss: 0.7646992206573486 lr : 0.000009 \n",
      "Loss: 0.3379214406013489 lr : 0.000009 \n",
      "Loss: 1.1487208604812622 lr : 0.000009 \n",
      "Loss: 0.670352578163147 lr : 0.000009 \n",
      "Loss: 0.7547695636749268 lr : 0.000009 \n",
      "Loss: 0.8807129859924316 lr : 0.000009 \n",
      "Loss: 0.5961267948150635 lr : 0.000009 \n",
      "Loss: 0.4646020233631134 lr : 0.000009 \n",
      "Loss: 0.4836542308330536 lr : 0.000009 \n",
      "Loss: 0.966471254825592 lr : 0.000009 \n",
      "Loss: 0.8238568902015686 lr : 0.000009 \n",
      "Loss: 1.2271074056625366 lr : 0.000009 \n",
      "Loss: 0.4333460032939911 lr : 0.000009 \n",
      "Loss: 0.7286176085472107 lr : 0.000009 \n",
      "Loss: 1.2836114168167114 lr : 0.000009 \n",
      "Loss: 1.175410509109497 lr : 0.000009 \n",
      "Loss: 1.070758581161499 lr : 0.000009 \n",
      "Loss: 0.6903761029243469 lr : 0.000009 \n",
      "Loss: 0.8782840967178345 lr : 0.000009 \n",
      "Loss: 1.0794947147369385 lr : 0.000009 \n",
      "Loss: 0.7128785252571106 lr : 0.000009 \n",
      "Loss: 0.3762425482273102 lr : 0.000009 \n",
      "Loss: 1.206700086593628 lr : 0.000009 \n",
      "Loss: 0.371978223323822 lr : 0.000009 \n",
      "Loss: 0.3269690275192261 lr : 0.000009 \n",
      "Loss: 0.4423340857028961 lr : 0.000009 \n",
      "Loss: 0.7241131067276001 lr : 0.000009 \n",
      "Loss: 0.8754884004592896 lr : 0.000009 \n",
      "Loss: 1.020412802696228 lr : 0.000009 \n",
      "Loss: 0.8981841206550598 lr : 0.000009 \n",
      "Loss: 0.6038704514503479 lr : 0.000009 \n",
      "Loss: 0.6183786988258362 lr : 0.000009 \n",
      "Loss: 0.8944740295410156 lr : 0.000009 \n",
      "Loss: 0.7691794633865356 lr : 0.000009 \n",
      "Loss: 0.7735620737075806 lr : 0.000009 \n",
      "Loss: 0.8668513298034668 lr : 0.000009 \n",
      "Loss: 0.31796109676361084 lr : 0.000009 \n",
      "Loss: 0.8870816230773926 lr : 0.000009 \n",
      "Loss: 1.0914771556854248 lr : 0.000009 \n",
      "Loss: 0.9522632360458374 lr : 0.000009 \n",
      "Loss: 0.3998386263847351 lr : 0.000009 \n",
      "Loss: 1.2660753726959229 lr : 0.000009 \n",
      "Loss: 0.6428747177124023 lr : 0.000009 \n",
      "Loss: 0.7610385417938232 lr : 0.000009 \n",
      "Loss: 0.47015419602394104 lr : 0.000009 \n",
      "Loss: 0.43972790241241455 lr : 0.000009 \n",
      "Loss: 0.9596407413482666 lr : 0.000009 \n",
      "Loss: 0.7540996074676514 lr : 0.000009 \n",
      "Loss: 0.8876796364784241 lr : 0.000009 \n",
      "Loss: 1.3324947357177734 lr : 0.000009 \n",
      "Loss: 1.0706923007965088 lr : 0.000009 \n",
      "Loss: 0.7333180904388428 lr : 0.000009 \n",
      "Loss: 0.4947723150253296 lr : 0.000009 \n",
      "Loss: 1.221749186515808 lr : 0.000009 \n",
      "Loss: 1.2131752967834473 lr : 0.000009 \n",
      "Loss: 0.7851994037628174 lr : 0.000009 \n",
      "Loss: 0.7619454264640808 lr : 0.000009 \n",
      "Loss: 0.7515564560890198 lr : 0.000009 \n",
      "Loss: 0.6491824984550476 lr : 0.000009 \n",
      "Loss: 0.2770644426345825 lr : 0.000009 \n",
      "Loss: 0.3310793936252594 lr : 0.000009 \n",
      "Loss: 0.5083539485931396 lr : 0.000009 \n",
      "Loss: 0.8523791432380676 lr : 0.000009 \n",
      "Loss: 0.8446337580680847 lr : 0.000009 \n",
      "Loss: 1.175072193145752 lr : 0.000009 \n",
      "Loss: 1.074723243713379 lr : 0.000009 \n",
      "Loss: 0.38607490062713623 lr : 0.000009 \n",
      "Loss: 1.084528923034668 lr : 0.000009 \n",
      "Loss: 0.8730493783950806 lr : 0.000009 \n",
      "Loss: 0.6437538266181946 lr : 0.000009 \n",
      "Loss: 1.2867343425750732 lr : 0.000009 \n",
      "Loss: 0.40815404057502747 lr : 0.000009 \n",
      "Loss: 1.5739985704421997 lr : 0.000009 \n",
      "Loss: 0.7027148604393005 lr : 0.000009 \n",
      "Loss: 0.7566049098968506 lr : 0.000009 \n",
      "Loss: 0.8317710757255554 lr : 0.000009 \n",
      "Loss: 0.34473976492881775 lr : 0.000009 \n",
      "Loss: 0.5318809151649475 lr : 0.000009 \n",
      "Loss: 0.6305820941925049 lr : 0.000009 \n",
      "Loss: 0.7439716458320618 lr : 0.000009 \n",
      "Loss: 0.7637330889701843 lr : 0.000009 \n",
      "Loss: 0.7932448387145996 lr : 0.000009 \n",
      "Loss: 0.6720057129859924 lr : 0.000009 \n",
      "Loss: 0.30351221561431885 lr : 0.000009 \n",
      "Loss: 0.5703446865081787 lr : 0.000009 \n",
      "Loss: 0.6241148710250854 lr : 0.000009 \n",
      "Loss: 0.4451355040073395 lr : 0.000009 \n",
      "Loss: 0.7305910587310791 lr : 0.000009 \n",
      "Loss: 0.5306838154792786 lr : 0.000009 \n",
      "Loss: 0.8581151366233826 lr : 0.000009 \n",
      "Loss: 0.8191021680831909 lr : 0.000009 \n",
      "Loss: 0.5693273544311523 lr : 0.000009 \n",
      "Loss: 0.788607656955719 lr : 0.000009 \n",
      "Loss: 0.6033417582511902 lr : 0.000009 \n",
      "Loss: 0.6929919719696045 lr : 0.000009 \n",
      "Loss: 0.6828949451446533 lr : 0.000009 \n",
      "Loss: 1.0037692785263062 lr : 0.000009 \n",
      "Loss: 0.444378137588501 lr : 0.000009 \n",
      "Loss: 0.6763738989830017 lr : 0.000009 \n",
      "Loss: 1.1038898229599 lr : 0.000009 \n",
      "Loss: 0.3569566011428833 lr : 0.000009 \n",
      "Loss: 1.6866976022720337 lr : 0.000009 \n",
      "Loss: 1.2116541862487793 lr : 0.000009 \n",
      "Loss: 1.1404757499694824 lr : 0.000009 \n",
      "Loss: 0.592975378036499 lr : 0.000009 \n",
      "Loss: 0.8304749727249146 lr : 0.000009 \n",
      "Loss: 0.8554892539978027 lr : 0.000009 \n",
      "Loss: 0.2618980407714844 lr : 0.000009 \n",
      "Loss: 0.7921789288520813 lr : 0.000009 \n",
      "Loss: 1.0847183465957642 lr : 0.000009 \n",
      "Loss: 0.9488549828529358 lr : 0.000009 \n",
      "Loss: 0.9808294773101807 lr : 0.000009 \n",
      "Loss: 0.7262092232704163 lr : 0.000009 \n",
      "Loss: 0.7223861813545227 lr : 0.000009 \n",
      "Loss: 0.6151000261306763 lr : 0.000009 \n",
      "Loss: 0.9351322650909424 lr : 0.000009 \n",
      "Loss: 0.6697538495063782 lr : 0.000009 \n",
      "Loss: 1.0817021131515503 lr : 0.000009 \n",
      "Loss: 0.8611674904823303 lr : 0.000009 \n",
      "Loss: 0.7574840784072876 lr : 0.000009 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4050387740135193 lr : 0.000009 \n",
      "Loss: 1.107010841369629 lr : 0.000009 \n",
      "Loss: 0.23013031482696533 lr : 0.000009 \n",
      "Loss: 1.1122790575027466 lr : 0.000009 \n",
      "Loss: 0.5626463890075684 lr : 0.000009 \n",
      "Loss: 1.1351053714752197 lr : 0.000009 \n",
      "Loss: 0.5769360065460205 lr : 0.000009 \n",
      "Loss: 1.1357449293136597 lr : 0.000009 \n",
      "Loss: 0.7697697877883911 lr : 0.000009 \n",
      "Loss: 0.7477922439575195 lr : 0.000009 \n",
      "Loss: 0.8572719097137451 lr : 0.000009 \n",
      "Loss: 0.6417900919914246 lr : 0.000009 \n",
      "Loss: 0.6547920107841492 lr : 0.000009 \n",
      "Loss: 0.5609573721885681 lr : 0.000009 \n",
      "Loss: 1.3102010488510132 lr : 0.000009 \n",
      "Loss: 0.9055250883102417 lr : 0.000009 \n",
      "Loss: 1.0428696870803833 lr : 0.000009 \n",
      "Loss: 0.0032809986732900143 lr : 0.000009 \n",
      "Loss: 1.142601728439331 lr : 0.000009 \n",
      "Loss: 0.47688549757003784 lr : 0.000009 \n",
      "Loss: 0.8381931781768799 lr : 0.000009 \n",
      "Loss: 1.4493244886398315 lr : 0.000009 \n",
      "Loss: 0.9181467890739441 lr : 0.000009 \n",
      "Loss: 0.7186872363090515 lr : 0.000009 \n",
      "Loss: 0.6988481283187866 lr : 0.000009 \n",
      "Loss: 0.30922073125839233 lr : 0.000009 \n",
      "Loss: 0.5583412051200867 lr : 0.000009 \n",
      "Loss: 1.2173558473587036 lr : 0.000009 \n",
      "Loss: 1.0049793720245361 lr : 0.000009 \n",
      "Loss: 0.4386935532093048 lr : 0.000009 \n",
      "Loss: 0.7137320637702942 lr : 0.000009 \n",
      "Loss: 0.5689360499382019 lr : 0.000009 \n",
      "Loss: 0.66017746925354 lr : 0.000009 \n",
      "Loss: 0.9032306671142578 lr : 0.000009 \n",
      "Loss: 0.6658073663711548 lr : 0.000009 \n",
      "Loss: 1.0815865993499756 lr : 0.000009 \n",
      "Loss: 0.7636721730232239 lr : 0.000009 \n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08e196ee37246339aafa392cc8a3c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7235326766967773 lr : 0.000009 \n",
      "Loss: 1.192431926727295 lr : 0.000009 \n",
      "Loss: 0.6627061367034912 lr : 0.000009 \n",
      "Loss: 0.5902383923530579 lr : 0.000009 \n",
      "Loss: 0.8919805288314819 lr : 0.000009 \n",
      "Loss: 1.015995740890503 lr : 0.000009 \n",
      "Loss: 0.5488107204437256 lr : 0.000009 \n",
      "Loss: 0.6607364416122437 lr : 0.000008 \n",
      "Loss: 1.4169526100158691 lr : 0.000008 \n",
      "Loss: 0.955756425857544 lr : 0.000008 \n",
      "Loss: 0.8035165071487427 lr : 0.000008 \n",
      "Loss: 1.1968417167663574 lr : 0.000008 \n",
      "Loss: 0.6570849418640137 lr : 0.000008 \n",
      "Loss: 1.0051250457763672 lr : 0.000008 \n",
      "Loss: 0.6556007862091064 lr : 0.000008 \n",
      "Loss: 0.6258431673049927 lr : 0.000008 \n",
      "Loss: 0.8131260275840759 lr : 0.000008 \n",
      "Loss: 1.1318644285202026 lr : 0.000008 \n",
      "Loss: 0.44483518600463867 lr : 0.000008 \n",
      "Loss: 0.7023304104804993 lr : 0.000008 \n",
      "Loss: 0.8564227819442749 lr : 0.000008 \n",
      "Loss: 0.999812662601471 lr : 0.000008 \n",
      "Loss: 0.845029354095459 lr : 0.000008 \n",
      "Loss: 1.015466570854187 lr : 0.000008 \n",
      "Loss: 1.106616497039795 lr : 0.000008 \n",
      "Loss: 0.6447694301605225 lr : 0.000008 \n",
      "Loss: 1.1401302814483643 lr : 0.000008 \n",
      "Loss: 0.6930698752403259 lr : 0.000008 \n",
      "Loss: 0.36183595657348633 lr : 0.000008 \n",
      "Loss: 1.1672166585922241 lr : 0.000008 \n",
      "Loss: 0.6001803278923035 lr : 0.000008 \n",
      "Loss: 0.9552174806594849 lr : 0.000008 \n",
      "Loss: 0.9795924425125122 lr : 0.000008 \n",
      "Loss: 0.3327734172344208 lr : 0.000008 \n",
      "Loss: 0.39520496129989624 lr : 0.000008 \n",
      "Loss: 0.6611452698707581 lr : 0.000008 \n",
      "Loss: 0.7138288021087646 lr : 0.000008 \n",
      "Loss: 0.3834291696548462 lr : 0.000008 \n",
      "Loss: 0.9974228739738464 lr : 0.000008 \n",
      "Loss: 0.5300815105438232 lr : 0.000008 \n",
      "Loss: 0.4891187846660614 lr : 0.000008 \n",
      "Loss: 1.1168910264968872 lr : 0.000008 \n",
      "Loss: 0.6435214877128601 lr : 0.000008 \n",
      "Loss: 1.0029256343841553 lr : 0.000008 \n",
      "Loss: 0.459429532289505 lr : 0.000008 \n",
      "Loss: 0.5952255725860596 lr : 0.000008 \n",
      "Loss: 0.5298939347267151 lr : 0.000008 \n",
      "Loss: 1.2512762546539307 lr : 0.000008 \n",
      "Loss: 0.6344082951545715 lr : 0.000008 \n",
      "Loss: 0.9921015501022339 lr : 0.000008 \n",
      "Loss: 0.8407730460166931 lr : 0.000008 \n",
      "Loss: 1.3180785179138184 lr : 0.000008 \n",
      "Loss: 0.9150944948196411 lr : 0.000008 \n",
      "Loss: 0.2790636718273163 lr : 0.000008 \n",
      "Loss: 0.7496114373207092 lr : 0.000008 \n",
      "Loss: 0.2843566834926605 lr : 0.000008 \n",
      "Loss: 0.9303165674209595 lr : 0.000008 \n",
      "Loss: 1.1388343572616577 lr : 0.000008 \n",
      "Loss: 0.5887868404388428 lr : 0.000008 \n",
      "Loss: 0.7906174659729004 lr : 0.000008 \n",
      "Loss: 1.295989751815796 lr : 0.000008 \n",
      "Loss: 0.41385453939437866 lr : 0.000008 \n",
      "Loss: 1.3520443439483643 lr : 0.000008 \n",
      "Loss: 0.3368483781814575 lr : 0.000008 \n",
      "Loss: 0.7942942976951599 lr : 0.000008 \n",
      "Loss: 0.7429047226905823 lr : 0.000008 \n",
      "Loss: 1.0839574337005615 lr : 0.000008 \n",
      "Loss: 1.1962302923202515 lr : 0.000008 \n",
      "Loss: 0.7239795327186584 lr : 0.000008 \n",
      "Loss: 0.7956257462501526 lr : 0.000008 \n",
      "Loss: 0.6070035099983215 lr : 0.000008 \n",
      "Loss: 1.3912477493286133 lr : 0.000008 \n",
      "Loss: 1.0314298868179321 lr : 0.000008 \n",
      "Loss: 0.7212736010551453 lr : 0.000008 \n",
      "Loss: 0.3825530707836151 lr : 0.000008 \n",
      "Loss: 0.8933706879615784 lr : 0.000008 \n",
      "Loss: 0.7700223326683044 lr : 0.000008 \n",
      "Loss: 0.934371829032898 lr : 0.000008 \n",
      "Loss: 0.9522045850753784 lr : 0.000008 \n",
      "Loss: 0.7544246315956116 lr : 0.000008 \n",
      "Loss: 0.5890868306159973 lr : 0.000008 \n",
      "Loss: 0.7331491708755493 lr : 0.000008 \n",
      "Loss: 0.3231455683708191 lr : 0.000008 \n",
      "Loss: 0.7770612239837646 lr : 0.000008 \n",
      "Loss: 1.4806631803512573 lr : 0.000008 \n",
      "Loss: 0.9567328691482544 lr : 0.000008 \n",
      "Loss: 0.9100723266601562 lr : 0.000008 \n",
      "Loss: 0.7950339913368225 lr : 0.000008 \n",
      "Loss: 0.7460841536521912 lr : 0.000008 \n",
      "Loss: 0.46310558915138245 lr : 0.000008 \n",
      "Loss: 0.33350223302841187 lr : 0.000008 \n",
      "Loss: 0.4090490937232971 lr : 0.000008 \n",
      "Loss: 0.9003361463546753 lr : 0.000008 \n",
      "Loss: 0.9920434355735779 lr : 0.000008 \n",
      "Loss: 0.646223247051239 lr : 0.000008 \n",
      "Loss: 0.5881426334381104 lr : 0.000008 \n",
      "Loss: 0.822885274887085 lr : 0.000008 \n",
      "Loss: 0.693194568157196 lr : 0.000008 \n",
      "Loss: 0.3532251715660095 lr : 0.000008 \n",
      "Loss: 0.4575359523296356 lr : 0.000008 \n",
      "Loss: 0.7323814034461975 lr : 0.000008 \n",
      "Loss: 1.0866150856018066 lr : 0.000008 \n",
      "Loss: 0.5149204730987549 lr : 0.000008 \n",
      "Loss: 0.8430010676383972 lr : 0.000008 \n",
      "Loss: 0.6798381805419922 lr : 0.000008 \n",
      "Loss: 1.2604647874832153 lr : 0.000008 \n",
      "Loss: 0.9333233833312988 lr : 0.000008 \n",
      "Loss: 1.1430977582931519 lr : 0.000008 \n",
      "Loss: 1.0193116664886475 lr : 0.000008 \n",
      "Loss: 0.3932684361934662 lr : 0.000008 \n",
      "Loss: 0.226281076669693 lr : 0.000008 \n",
      "Loss: 0.8941000699996948 lr : 0.000008 \n",
      "Loss: 1.039048194885254 lr : 0.000008 \n",
      "Loss: 1.0984920263290405 lr : 0.000008 \n",
      "Loss: 1.2068554162979126 lr : 0.000008 \n",
      "Loss: 0.9566017985343933 lr : 0.000008 \n",
      "Loss: 0.6847743391990662 lr : 0.000008 \n",
      "Loss: 0.7709304690361023 lr : 0.000008 \n",
      "Loss: 0.6753402948379517 lr : 0.000008 \n",
      "Loss: 0.6147950887680054 lr : 0.000008 \n",
      "Loss: 0.8420409560203552 lr : 0.000008 \n",
      "Loss: 0.7359448671340942 lr : 0.000008 \n",
      "Loss: 0.7179812788963318 lr : 0.000008 \n",
      "Loss: 0.5157872438430786 lr : 0.000008 \n",
      "Loss: 1.2173336744308472 lr : 0.000008 \n",
      "Loss: 0.5191036462783813 lr : 0.000008 \n",
      "Loss: 1.0122536420822144 lr : 0.000008 \n",
      "Loss: 1.2043768167495728 lr : 0.000008 \n",
      "Loss: 0.8054144382476807 lr : 0.000008 \n",
      "Loss: 1.2957396507263184 lr : 0.000008 \n",
      "Loss: 0.9546301364898682 lr : 0.000008 \n",
      "Loss: 1.2646019458770752 lr : 0.000008 \n",
      "Loss: 0.5024199485778809 lr : 0.000008 \n",
      "Loss: 0.6809525489807129 lr : 0.000008 \n",
      "Loss: 0.6737911701202393 lr : 0.000008 \n",
      "Loss: 0.47503969073295593 lr : 0.000008 \n",
      "Loss: 0.6408324241638184 lr : 0.000008 \n",
      "Loss: 0.7488353848457336 lr : 0.000008 \n",
      "Loss: 1.1300302743911743 lr : 0.000008 \n",
      "Loss: 1.0355345010757446 lr : 0.000008 \n",
      "Loss: 1.3377406597137451 lr : 0.000008 \n",
      "Loss: 0.9691451191902161 lr : 0.000008 \n",
      "Loss: 0.22804386913776398 lr : 0.000008 \n",
      "Loss: 0.6721396446228027 lr : 0.000008 \n",
      "Loss: 0.7510436177253723 lr : 0.000008 \n",
      "Loss: 1.1264439821243286 lr : 0.000008 \n",
      "Loss: 0.6749756336212158 lr : 0.000008 \n",
      "Loss: 0.33288779854774475 lr : 0.000008 \n",
      "Loss: 0.6126770377159119 lr : 0.000008 \n",
      "Loss: 1.16188383102417 lr : 0.000008 \n",
      "Loss: 0.5078420639038086 lr : 0.000008 \n",
      "Loss: 0.674223005771637 lr : 0.000008 \n",
      "Loss: 1.222856879234314 lr : 0.000008 \n",
      "Loss: 0.17244209349155426 lr : 0.000008 \n",
      "Loss: 0.8617293238639832 lr : 0.000008 \n",
      "Loss: 0.8532029986381531 lr : 0.000008 \n",
      "Loss: 1.0151008367538452 lr : 0.000008 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.118545413017273 lr : 0.000007 \n",
      "Loss: 0.5234410166740417 lr : 0.000007 \n",
      "Loss: 0.28771212697029114 lr : 0.000007 \n",
      "Loss: 0.6947903633117676 lr : 0.000007 \n",
      "Loss: 0.8874111175537109 lr : 0.000007 \n",
      "Loss: 0.6647882461547852 lr : 0.000007 \n",
      "Loss: 0.811589777469635 lr : 0.000007 \n",
      "Loss: 0.8131832480430603 lr : 0.000007 \n",
      "Loss: 0.48346948623657227 lr : 0.000007 \n",
      "Loss: 0.6390827894210815 lr : 0.000007 \n",
      "Loss: 0.6688669323921204 lr : 0.000007 \n",
      "Loss: 0.5917144417762756 lr : 0.000007 \n",
      "Loss: 1.029126763343811 lr : 0.000007 \n",
      "Loss: 0.7917524576187134 lr : 0.000007 \n",
      "Loss: 0.887781023979187 lr : 0.000007 \n",
      "Loss: 0.6180808544158936 lr : 0.000007 \n",
      "Loss: 0.9798905849456787 lr : 0.000007 \n",
      "Loss: 0.5652866363525391 lr : 0.000007 \n",
      "Loss: 0.6522808074951172 lr : 0.000007 \n",
      "Loss: 1.161333680152893 lr : 0.000007 \n",
      "Loss: 0.639288067817688 lr : 0.000007 \n",
      "Loss: 1.4931292533874512 lr : 0.000007 \n",
      "Loss: 0.5799635648727417 lr : 0.000007 \n",
      "Loss: 1.0596197843551636 lr : 0.000007 \n",
      "Loss: 0.8263518810272217 lr : 0.000007 \n",
      "Loss: 0.6344776749610901 lr : 0.000007 \n",
      "Loss: 0.7162884473800659 lr : 0.000007 \n",
      "Loss: 0.612604022026062 lr : 0.000007 \n",
      "Loss: 0.7375295162200928 lr : 0.000007 \n",
      "Loss: 0.836435854434967 lr : 0.000007 \n",
      "Loss: 0.765404462814331 lr : 0.000007 \n",
      "Loss: 0.664249062538147 lr : 0.000007 \n",
      "Loss: 1.1406712532043457 lr : 0.000007 \n",
      "Loss: 1.1144098043441772 lr : 0.000007 \n",
      "Loss: 1.102914571762085 lr : 0.000007 \n",
      "Loss: 0.9258383512496948 lr : 0.000007 \n",
      "Loss: 0.8977682590484619 lr : 0.000007 \n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ade45a04d342d39bd77d4aa7f08319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7634539008140564 lr : 0.000007 \n",
      "Loss: 0.15728087723255157 lr : 0.000007 \n",
      "Loss: 0.6131327152252197 lr : 0.000007 \n",
      "Loss: 0.8122766613960266 lr : 0.000007 \n",
      "Loss: 0.6121813058853149 lr : 0.000007 \n",
      "Loss: 1.1065603494644165 lr : 0.000007 \n",
      "Loss: 0.13333803415298462 lr : 0.000007 \n",
      "Loss: 1.0836213827133179 lr : 0.000007 \n",
      "Loss: 0.7383244037628174 lr : 0.000007 \n",
      "Loss: 1.1530327796936035 lr : 0.000007 \n",
      "Loss: 0.5047546029090881 lr : 0.000007 \n",
      "Loss: 0.8137045502662659 lr : 0.000007 \n",
      "Loss: 0.8050179481506348 lr : 0.000007 \n",
      "Loss: 0.9557466506958008 lr : 0.000007 \n",
      "Loss: 0.5749271512031555 lr : 0.000007 \n",
      "Loss: 0.33513879776000977 lr : 0.000007 \n",
      "Loss: 0.3584668040275574 lr : 0.000007 \n",
      "Loss: 0.36349427700042725 lr : 0.000007 \n",
      "Loss: 0.5554749965667725 lr : 0.000007 \n",
      "Loss: 1.5390669107437134 lr : 0.000007 \n",
      "Loss: 0.40759602189064026 lr : 0.000007 \n",
      "Loss: 0.6623473167419434 lr : 0.000007 \n",
      "Loss: 0.6113099455833435 lr : 0.000007 \n",
      "Loss: 1.3107919692993164 lr : 0.000007 \n",
      "Loss: 0.34883350133895874 lr : 0.000007 \n",
      "Loss: 0.14230477809906006 lr : 0.000007 \n",
      "Loss: 1.1584441661834717 lr : 0.000007 \n",
      "Loss: 1.0621118545532227 lr : 0.000007 \n",
      "Loss: 0.8523611426353455 lr : 0.000007 \n",
      "Loss: 1.091892123222351 lr : 0.000007 \n",
      "Loss: 0.3009231984615326 lr : 0.000007 \n",
      "Loss: 0.32837700843811035 lr : 0.000007 \n",
      "Loss: 0.6909545660018921 lr : 0.000007 \n",
      "Loss: 0.8293353915214539 lr : 0.000007 \n",
      "Loss: 0.9383801221847534 lr : 0.000007 \n",
      "Loss: 0.6279093027114868 lr : 0.000007 \n",
      "Loss: 0.7418133616447449 lr : 0.000007 \n",
      "Loss: 1.0689154863357544 lr : 0.000007 \n",
      "Loss: 1.3711185455322266 lr : 0.000007 \n",
      "Loss: 0.540472149848938 lr : 0.000007 \n",
      "Loss: 0.9946897029876709 lr : 0.000007 \n",
      "Loss: 0.9138046503067017 lr : 0.000007 \n",
      "Loss: 1.102310061454773 lr : 0.000007 \n",
      "Loss: 0.845055103302002 lr : 0.000007 \n",
      "Loss: 1.0500987768173218 lr : 0.000007 \n",
      "Loss: 0.8614183664321899 lr : 0.000007 \n",
      "Loss: 0.6133167147636414 lr : 0.000007 \n",
      "Loss: 0.8496971130371094 lr : 0.000007 \n",
      "Loss: 0.5982024669647217 lr : 0.000007 \n",
      "Loss: 1.2735888957977295 lr : 0.000007 \n",
      "Loss: 1.0128231048583984 lr : 0.000007 \n",
      "Loss: 0.7571553587913513 lr : 0.000007 \n",
      "Loss: 0.3482199013233185 lr : 0.000007 \n",
      "Loss: 0.17306554317474365 lr : 0.000007 \n",
      "Loss: 0.6138693690299988 lr : 0.000007 \n",
      "Loss: 1.2571297883987427 lr : 0.000006 \n",
      "Loss: 0.708421528339386 lr : 0.000006 \n",
      "Loss: 1.1710915714502335e-05 lr : 0.000006 \n",
      "Loss: 0.7745358347892761 lr : 0.000006 \n",
      "Loss: 0.5789747834205627 lr : 0.000006 \n",
      "Loss: 0.3274182975292206 lr : 0.000006 \n",
      "Loss: 0.607801079750061 lr : 0.000006 \n",
      "Loss: 0.808648407459259 lr : 0.000006 \n",
      "Loss: 1.1487399339675903 lr : 0.000006 \n",
      "Loss: 0.6741940975189209 lr : 0.000006 \n",
      "Loss: 1.3511494398117065 lr : 0.000006 \n",
      "Loss: 1.0135464668273926 lr : 0.000006 \n",
      "Loss: 0.843926727771759 lr : 0.000006 \n",
      "Loss: 0.5680803656578064 lr : 0.000006 \n",
      "Loss: 0.36567553877830505 lr : 0.000006 \n",
      "Loss: 0.5718338489532471 lr : 0.000006 \n",
      "Loss: 0.49503016471862793 lr : 0.000006 \n",
      "Loss: 0.41158774495124817 lr : 0.000006 \n",
      "Loss: 1.2279025316238403 lr : 0.000006 \n",
      "Loss: 0.3912361264228821 lr : 0.000006 \n",
      "Loss: 0.663047730922699 lr : 0.000006 \n",
      "Loss: 0.7932093143463135 lr : 0.000006 \n",
      "Loss: 1.5478770732879639 lr : 0.000006 \n",
      "Loss: 1.015894889831543 lr : 0.000006 \n",
      "Loss: 1.2622299194335938 lr : 0.000006 \n",
      "Loss: 1.2810003757476807 lr : 0.000006 \n",
      "Loss: 1.0701396465301514 lr : 0.000006 \n",
      "Loss: 1.5310173034667969 lr : 0.000006 \n",
      "Loss: 0.7705622911453247 lr : 0.000006 \n",
      "Loss: 1.067429780960083 lr : 0.000006 \n",
      "Loss: 1.0339024066925049 lr : 0.000006 \n",
      "Loss: 0.4343719482421875 lr : 0.000006 \n",
      "Loss: 0.47660529613494873 lr : 0.000006 \n",
      "Loss: 0.38012295961380005 lr : 0.000006 \n",
      "Loss: 0.4125744700431824 lr : 0.000006 \n",
      "Loss: 1.2743799686431885 lr : 0.000006 \n",
      "Loss: 0.6230438947677612 lr : 0.000006 \n",
      "Loss: 0.39366263151168823 lr : 0.000006 \n",
      "Loss: 0.17518724501132965 lr : 0.000006 \n",
      "Loss: 0.9606854319572449 lr : 0.000006 \n",
      "Loss: 0.8735591769218445 lr : 0.000006 \n",
      "Loss: 1.0362910032272339 lr : 0.000006 \n",
      "Loss: 0.833922803401947 lr : 0.000006 \n",
      "Loss: 0.8311662673950195 lr : 0.000006 \n",
      "Loss: 0.8005887269973755 lr : 0.000006 \n",
      "Loss: 0.9479275345802307 lr : 0.000006 \n",
      "Loss: 0.5633388161659241 lr : 0.000006 \n",
      "Loss: 1.0688378810882568 lr : 0.000006 \n",
      "Loss: 0.6311447024345398 lr : 0.000006 \n",
      "Loss: 0.6576643586158752 lr : 0.000006 \n",
      "Loss: 0.4676154851913452 lr : 0.000006 \n",
      "Loss: 0.6520695686340332 lr : 0.000006 \n",
      "Loss: 0.7172695994377136 lr : 0.000006 \n",
      "Loss: 1.020370602607727 lr : 0.000006 \n",
      "Loss: 0.36882278323173523 lr : 0.000006 \n",
      "Loss: 0.7365593314170837 lr : 0.000006 \n",
      "Loss: 0.32734715938568115 lr : 0.000006 \n",
      "Loss: 0.5386644005775452 lr : 0.000006 \n",
      "Loss: 0.8299515247344971 lr : 0.000006 \n",
      "Loss: 1.3920917510986328 lr : 0.000006 \n",
      "Loss: 0.7971307039260864 lr : 0.000006 \n",
      "Loss: 0.9816519021987915 lr : 0.000006 \n",
      "Loss: 0.33574801683425903 lr : 0.000006 \n",
      "Loss: 0.5472732782363892 lr : 0.000006 \n",
      "Loss: 0.5730172395706177 lr : 0.000006 \n",
      "Loss: 0.8039748668670654 lr : 0.000006 \n",
      "Loss: 0.8090288639068604 lr : 0.000006 \n",
      "Loss: 0.5492576956748962 lr : 0.000006 \n",
      "Loss: 0.82220059633255 lr : 0.000006 \n",
      "Loss: 0.2684274911880493 lr : 0.000006 \n",
      "Loss: 0.865723192691803 lr : 0.000006 \n",
      "Loss: 0.38438475131988525 lr : 0.000006 \n",
      "Loss: 0.7768024206161499 lr : 0.000006 \n",
      "Loss: 0.7970796823501587 lr : 0.000006 \n",
      "Loss: 0.6378529071807861 lr : 0.000006 \n",
      "Loss: 0.7945762872695923 lr : 0.000006 \n",
      "Loss: 0.5082243084907532 lr : 0.000006 \n",
      "Loss: 0.6773598194122314 lr : 0.000006 \n",
      "Loss: 1.2746636867523193 lr : 0.000006 \n",
      "Loss: 0.7197600603103638 lr : 0.000006 \n",
      "Loss: 0.876567006111145 lr : 0.000006 \n",
      "Loss: 0.3284607529640198 lr : 0.000006 \n",
      "Loss: 1.1362208127975464 lr : 0.000006 \n",
      "Loss: 1.1906623840332031 lr : 0.000006 \n",
      "Loss: 0.7482571601867676 lr : 0.000006 \n",
      "Loss: 0.7948310375213623 lr : 0.000006 \n",
      "Loss: 0.3489767014980316 lr : 0.000006 \n",
      "Loss: 0.2728089690208435 lr : 0.000006 \n",
      "Loss: 0.736877977848053 lr : 0.000006 \n",
      "Loss: 0.6752205491065979 lr : 0.000006 \n",
      "Loss: 0.7003282904624939 lr : 0.000006 \n",
      "Loss: 0.7634710669517517 lr : 0.000006 \n",
      "Loss: 0.8230317831039429 lr : 0.000006 \n",
      "Loss: 0.18722490966320038 lr : 0.000006 \n",
      "Loss: 0.5963226556777954 lr : 0.000006 \n",
      "Loss: 1.2983646392822266 lr : 0.000006 \n",
      "Loss: 0.8113272786140442 lr : 0.000006 \n",
      "Loss: 0.7356316447257996 lr : 0.000006 \n",
      "Loss: 1.1538923978805542 lr : 0.000006 \n",
      "Loss: 1.183508038520813 lr : 0.000006 \n",
      "Loss: 0.6007915139198303 lr : 0.000006 \n",
      "Loss: 0.7950541973114014 lr : 0.000006 \n",
      "Loss: 0.9694652557373047 lr : 0.000006 \n",
      "Loss: 0.3052118122577667 lr : 0.000006 \n",
      "Loss: 0.819024384021759 lr : 0.000006 \n",
      "Loss: 0.6532599925994873 lr : 0.000006 \n",
      "Loss: 0.7270761132240295 lr : 0.000006 \n",
      "Loss: 1.2759768962860107 lr : 0.000006 \n",
      "Loss: 0.7634086012840271 lr : 0.000006 \n",
      "Loss: 0.3344019651412964 lr : 0.000006 \n",
      "Loss: 1.0719090700149536 lr : 0.000006 \n",
      "Loss: 1.5585534572601318 lr : 0.000006 \n",
      "Loss: 0.5403023958206177 lr : 0.000006 \n",
      "Loss: 0.7019720077514648 lr : 0.000006 \n",
      "Loss: 1.096076250076294 lr : 0.000006 \n",
      "Loss: 0.5755901336669922 lr : 0.000006 \n",
      "Loss: 1.152248740196228 lr : 0.000006 \n",
      "Loss: 0.673026978969574 lr : 0.000006 \n",
      "Loss: 0.42077839374542236 lr : 0.000006 \n",
      "Loss: 1.0180104970932007 lr : 0.000006 \n",
      "Loss: 1.2055208683013916 lr : 0.000006 \n",
      "Loss: 0.7452327609062195 lr : 0.000006 \n",
      "Loss: 0.7651429772377014 lr : 0.000006 \n",
      "Loss: 1.0281544923782349 lr : 0.000006 \n",
      "Loss: 0.9396011829376221 lr : 0.000006 \n",
      "Loss: 5.4775853641331196e-05 lr : 0.000006 \n",
      "Loss: 0.5052101612091064 lr : 0.000005 \n",
      "Loss: 0.6622490286827087 lr : 0.000005 \n",
      "Loss: 0.38736167550086975 lr : 0.000005 \n",
      "Loss: 1.0911777019500732 lr : 0.000005 \n",
      "Loss: 0.8788464665412903 lr : 0.000005 \n",
      "Loss: 8.471321780234575e-05 lr : 0.000005 \n",
      "Loss: 0.643755316734314 lr : 0.000005 \n",
      "Loss: 0.9926422834396362 lr : 0.000005 \n",
      "Loss: 0.5169602632522583 lr : 0.000005 \n",
      "Loss: 4.926417022943497e-05 lr : 0.000005 \n",
      "Loss: 0.4273577928543091 lr : 0.000005 \n",
      "Loss: 0.7768009901046753 lr : 0.000005 \n",
      "Loss: 1.2227703332901 lr : 0.000005 \n",
      "Loss: 0.8421295881271362 lr : 0.000005 \n",
      "Loss: 0.6800179481506348 lr : 0.000005 \n",
      "Loss: 0.8394555449485779 lr : 0.000005 \n",
      "Loss: 0.6073355674743652 lr : 0.000005 \n",
      "Loss: 1.0572909116744995 lr : 0.000005 \n",
      "Loss: 1.1273688077926636 lr : 0.000005 \n",
      "Loss: 1.1408278942108154 lr : 0.000005 \n",
      "Loss: 0.9994394183158875 lr : 0.000005 \n",
      "Loss: 0.4970031678676605 lr : 0.000005 \n",
      "Loss: 0.5629289746284485 lr : 0.000005 \n",
      "Loss: 0.6453880071640015 lr : 0.000005 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5043783187866211 lr : 0.000005 \n",
      "Loss: 0.4951121211051941 lr : 0.000005 \n",
      "Loss: 0.7514123916625977 lr : 0.000005 \n",
      "Loss: 1.1417346000671387 lr : 0.000005 \n",
      "Loss: 0.6692086458206177 lr : 0.000005 \n",
      "Loss: 0.9038362503051758 lr : 0.000005 \n",
      "Loss: 0.46428561210632324 lr : 0.000005 \n",
      "Loss: 1.001158595085144 lr : 0.000005 \n",
      "Loss: 0.5371847152709961 lr : 0.000005 \n",
      "Loss: 0.519828736782074 lr : 0.000005 \n",
      "Loss: 0.6938729882240295 lr : 0.000005 \n",
      "Loss: 0.5223884582519531 lr : 0.000005 \n",
      "Loss: 0.7054895162582397 lr : 0.000005 \n",
      "Loss: 0.2997346818447113 lr : 0.000005 \n",
      "Loss: 0.5559055209159851 lr : 0.000005 \n",
      "Loss: 0.6503329873085022 lr : 0.000005 \n",
      "Loss: 0.9274314641952515 lr : 0.000005 \n",
      "Loss: 0.6246740818023682 lr : 0.000005 \n",
      "Loss: 0.4556489884853363 lr : 0.000005 \n",
      "Loss: 0.8858939409255981 lr : 0.000005 \n",
      "Loss: 0.7919100522994995 lr : 0.000005 \n",
      "Loss: 0.6550304889678955 lr : 0.000005 \n",
      "Loss: 0.43188223242759705 lr : 0.000005 \n",
      "Loss: 0.6248058676719666 lr : 0.000005 \n",
      "Loss: 0.41390520334243774 lr : 0.000005 \n",
      "Loss: 0.23566599190235138 lr : 0.000005 \n",
      "Loss: 0.5716596841812134 lr : 0.000005 \n",
      "Loss: 1.1979708671569824 lr : 0.000005 \n",
      "Loss: 0.661138117313385 lr : 0.000005 \n",
      "Loss: 1.176317572593689 lr : 0.000005 \n",
      "Loss: 1.2977871894836426 lr : 0.000005 \n",
      "Loss: 1.206404209136963 lr : 0.000005 \n",
      "Loss: 0.9926187992095947 lr : 0.000005 \n",
      "Loss: 0.9823864102363586 lr : 0.000005 \n",
      "Loss: 0.5300959348678589 lr : 0.000005 \n",
      "Loss: 0.7712110280990601 lr : 0.000005 \n",
      "Loss: 0.6470909118652344 lr : 0.000005 \n",
      "Loss: 0.36165282130241394 lr : 0.000005 \n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7b9a95b41b41609725c05d39e69b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6827391386032104 lr : 0.000005 \n",
      "Loss: 0.8731006979942322 lr : 0.000005 \n",
      "Loss: 0.5487709641456604 lr : 0.000005 \n",
      "Loss: 0.7064599394798279 lr : 0.000005 \n",
      "Loss: 0.6545484662055969 lr : 0.000005 \n",
      "Loss: 0.33575066924095154 lr : 0.000005 \n",
      "Loss: 0.42181992530822754 lr : 0.000005 \n",
      "Loss: 0.9168716669082642 lr : 0.000005 \n",
      "Loss: 0.5497962236404419 lr : 0.000005 \n",
      "Loss: 0.6182078123092651 lr : 0.000005 \n",
      "Loss: 1.1085460186004639 lr : 0.000005 \n",
      "Loss: 0.5720779895782471 lr : 0.000005 \n",
      "Loss: 0.17523843050003052 lr : 0.000005 \n",
      "Loss: 0.9560202360153198 lr : 0.000005 \n",
      "Loss: 1.1202325820922852 lr : 0.000005 \n",
      "Loss: 0.8056736588478088 lr : 0.000005 \n",
      "Loss: 0.32379767298698425 lr : 0.000005 \n",
      "Loss: 0.40775689482688904 lr : 0.000005 \n",
      "Loss: 0.7668707370758057 lr : 0.000005 \n",
      "Loss: 0.7287191152572632 lr : 0.000005 \n",
      "Loss: 0.5547690391540527 lr : 0.000005 \n",
      "Loss: 1.5502018928527832 lr : 0.000005 \n",
      "Loss: 0.7821994423866272 lr : 0.000005 \n",
      "Loss: 0.4362436830997467 lr : 0.000005 \n",
      "Loss: 0.816501796245575 lr : 0.000005 \n",
      "Loss: 0.47915172576904297 lr : 0.000005 \n",
      "Loss: 0.30293482542037964 lr : 0.000005 \n",
      "Loss: 2.501613926142454e-05 lr : 0.000005 \n",
      "Loss: 0.4885861277580261 lr : 0.000005 \n",
      "Loss: 0.714469313621521 lr : 0.000005 \n",
      "Loss: 0.6054713726043701 lr : 0.000005 \n",
      "Loss: 1.1073601245880127 lr : 0.000005 \n",
      "Loss: 0.6471542716026306 lr : 0.000005 \n",
      "Loss: 0.906057596206665 lr : 0.000005 \n",
      "Loss: 0.37721237540245056 lr : 0.000005 \n",
      "Loss: 0.6979749202728271 lr : 0.000005 \n",
      "Loss: 1.0140661001205444 lr : 0.000005 \n",
      "Loss: 0.3675876259803772 lr : 0.000005 \n",
      "Loss: 0.5042234659194946 lr : 0.000005 \n",
      "Loss: 0.8793768882751465 lr : 0.000005 \n",
      "Loss: 0.6635547280311584 lr : 0.000005 \n",
      "Loss: 0.5379112958908081 lr : 0.000005 \n",
      "Loss: 0.996806263923645 lr : 0.000005 \n",
      "Loss: 0.33137285709381104 lr : 0.000005 \n",
      "Loss: 0.8547136783599854 lr : 0.000005 \n",
      "Loss: 0.5309622287750244 lr : 0.000005 \n",
      "Loss: 0.6676332354545593 lr : 0.000005 \n",
      "Loss: 1.2029536962509155 lr : 0.000005 \n",
      "Loss: 0.6377386450767517 lr : 0.000005 \n",
      "Loss: 0.9386950135231018 lr : 0.000005 \n",
      "Loss: 0.426370769739151 lr : 0.000005 \n",
      "Loss: 1.1418958902359009 lr : 0.000005 \n",
      "Loss: 1.1945974826812744 lr : 0.000005 \n",
      "Loss: 0.6600134968757629 lr : 0.000005 \n",
      "Loss: 0.5310620069503784 lr : 0.000005 \n",
      "Loss: 0.9401071071624756 lr : 0.000005 \n",
      "Loss: 0.7396296858787537 lr : 0.000005 \n",
      "Loss: 0.4282810091972351 lr : 0.000005 \n",
      "Loss: 0.8165539503097534 lr : 0.000005 \n",
      "Loss: 1.1982579231262207 lr : 0.000005 \n",
      "Loss: 0.9423648715019226 lr : 0.000005 \n",
      "Loss: 1.3450132608413696 lr : 0.000005 \n",
      "Loss: 0.7922211289405823 lr : 0.000004 \n",
      "Loss: 1.2472525835037231 lr : 0.000004 \n",
      "Loss: 0.7904016971588135 lr : 0.000004 \n",
      "Loss: 0.7043699622154236 lr : 0.000004 \n",
      "Loss: 0.9070136547088623 lr : 0.000004 \n",
      "Loss: 0.7648933529853821 lr : 0.000004 \n",
      "Loss: 0.8591076135635376 lr : 0.000004 \n",
      "Loss: 0.823715090751648 lr : 0.000004 \n",
      "Loss: 0.3107479214668274 lr : 0.000004 \n",
      "Loss: 1.6407864093780518 lr : 0.000004 \n",
      "Loss: 0.42495766282081604 lr : 0.000004 \n",
      "Loss: 0.5676004886627197 lr : 0.000004 \n",
      "Loss: 0.1359977275133133 lr : 0.000004 \n",
      "Loss: 0.7639275789260864 lr : 0.000004 \n",
      "Loss: 0.844341516494751 lr : 0.000004 \n",
      "Loss: 0.9146988391876221 lr : 0.000004 \n",
      "Loss: 0.7988376617431641 lr : 0.000004 \n",
      "Loss: 0.33351126313209534 lr : 0.000004 \n",
      "Loss: 0.5539834499359131 lr : 0.000004 \n",
      "Loss: 0.6992422342300415 lr : 0.000004 \n",
      "Loss: 0.10667015612125397 lr : 0.000001 \n",
      "Loss: 1.6523288488388062 lr : 0.000001 \n",
      "Loss: 0.3435726761817932 lr : 0.000001 \n",
      "Loss: 0.6778247952461243 lr : 0.000001 \n",
      "Loss: 0.5670264363288879 lr : 0.000001 \n",
      "Loss: 0.9500220417976379 lr : 0.000001 \n",
      "Loss: 0.7445278763771057 lr : 0.000001 \n",
      "Loss: 0.3707715570926666 lr : 0.000001 \n",
      "Loss: 1.146930456161499 lr : 0.000001 \n",
      "Loss: 0.6943578124046326 lr : 0.000001 \n",
      "Loss: 0.849539041519165 lr : 0.000001 \n",
      "Loss: 1.0010355710983276 lr : 0.000001 \n",
      "Loss: 0.28993383049964905 lr : 0.000001 \n",
      "Loss: 0.44806110858917236 lr : 0.000001 \n",
      "Loss: 0.946239173412323 lr : 0.000001 \n",
      "Loss: 0.35286426544189453 lr : 0.000001 \n",
      "Loss: 0.3784947395324707 lr : 0.000001 \n",
      "Loss: 1.087916374206543 lr : 0.000001 \n",
      "Loss: 0.5445193648338318 lr : 0.000001 \n",
      "Loss: 0.6658719182014465 lr : 0.000001 \n",
      "Loss: 0.6136932969093323 lr : 0.000001 \n",
      "Loss: 1.0261883735656738 lr : 0.000001 \n",
      "Loss: 0.7678015828132629 lr : 0.000001 \n",
      "Loss: 0.5622692704200745 lr : 0.000001 \n",
      "Loss: 0.5952044725418091 lr : 0.000001 \n",
      "Loss: 0.7077536582946777 lr : 0.000001 \n",
      "Loss: 0.7478455305099487 lr : 0.000001 \n",
      "Loss: 0.5587083101272583 lr : 0.000001 \n",
      "Loss: 0.6658127307891846 lr : 0.000001 \n",
      "Loss: 0.9430088996887207 lr : 0.000001 \n",
      "Loss: 0.14179596304893494 lr : 0.000001 \n",
      "Loss: 0.28228557109832764 lr : 0.000001 \n",
      "Loss: 1.006056547164917 lr : 0.000001 \n",
      "Loss: 0.6355220675468445 lr : 0.000001 \n",
      "Loss: 0.47652655839920044 lr : 0.000001 \n",
      "Loss: 0.6385698318481445 lr : 0.000001 \n",
      "Loss: 0.8067218065261841 lr : 0.000001 \n",
      "Loss: 0.6868095397949219 lr : 0.000001 \n",
      "Loss: 0.579296886920929 lr : 0.000001 \n",
      "Loss: 0.7177553176879883 lr : 0.000001 \n",
      "Loss: 1.49158775806427 lr : 0.000001 \n",
      "Loss: 0.609207272529602 lr : 0.000001 \n",
      "Loss: 1.2286696434020996 lr : 0.000001 \n",
      "Loss: 0.6447439193725586 lr : 0.000001 \n",
      "Loss: 0.8794877529144287 lr : 0.000001 \n",
      "Loss: 0.2831917107105255 lr : 0.000001 \n",
      "Loss: 0.6393917798995972 lr : 0.000001 \n",
      "Loss: 0.8402233719825745 lr : 0.000001 \n",
      "Loss: 0.8282926678657532 lr : 0.000001 \n",
      "Loss: 0.7365805506706238 lr : 0.000001 \n",
      "Loss: 0.7111169695854187 lr : 0.000001 \n",
      "Loss: 0.8166121244430542 lr : 0.000001 \n",
      "Loss: 0.44733431935310364 lr : 0.000001 \n",
      "Loss: 0.2606598436832428 lr : 0.000001 \n",
      "Loss: 1.091843843460083 lr : 0.000001 \n",
      "Loss: 0.8712636828422546 lr : 0.000001 \n",
      "Loss: 0.7695598602294922 lr : 0.000001 \n",
      "Loss: 0.6272336840629578 lr : 0.000001 \n",
      "Loss: 1.2977102994918823 lr : 0.000001 \n",
      "Loss: 0.5248508453369141 lr : 0.000001 \n",
      "Loss: 0.7436652779579163 lr : 0.000001 \n",
      "Loss: 0.6771517395973206 lr : 0.000001 \n",
      "Loss: 1.08591628074646 lr : 0.000001 \n",
      "Loss: 1.0197525024414062 lr : 0.000001 \n",
      "Loss: 0.8073660135269165 lr : 0.000001 \n",
      "Loss: 0.6750816106796265 lr : 0.000001 \n",
      "Loss: 0.6659624576568604 lr : 0.000001 \n",
      "Loss: 0.8946195244789124 lr : 0.000001 \n",
      "Loss: 0.668193519115448 lr : 0.000001 \n",
      "Loss: 0.7982000112533569 lr : 0.000001 \n",
      "Loss: 1.3634463548660278 lr : 0.000001 \n",
      "Loss: 0.4350481927394867 lr : 0.000001 \n",
      "Loss: 0.2722541391849518 lr : 0.000001 \n",
      "Loss: 0.7274764776229858 lr : 0.000001 \n",
      "Loss: 0.2934969663619995 lr : 0.000001 \n",
      "Loss: 0.5596444606781006 lr : 0.000001 \n",
      "Loss: 0.5702061653137207 lr : 0.000001 \n",
      "Loss: 0.6421574950218201 lr : 0.000001 \n",
      "Loss: 0.7209858894348145 lr : 0.000001 \n",
      "Loss: 0.6810159683227539 lr : 0.000001 \n",
      "Loss: 1.2507375478744507 lr : 0.000001 \n",
      "Loss: 0.9330480098724365 lr : 0.000001 \n",
      "Loss: 1.3405107893049717e-05 lr : 0.000001 \n",
      "Loss: 1.1555311679840088 lr : 0.000001 \n",
      "Loss: 1.1163564920425415 lr : 0.000001 \n",
      "Loss: 0.7730897068977356 lr : 0.000001 \n",
      "Loss: 0.7131250500679016 lr : 0.000001 \n",
      "Loss: 0.401240736246109 lr : 0.000001 \n",
      "Loss: 1.0588833093643188 lr : 0.000001 \n",
      "Loss: 0.9244700074195862 lr : 0.000001 \n",
      "Loss: 0.45914793014526367 lr : 0.000001 \n",
      "Loss: 0.3323318362236023 lr : 0.000001 \n",
      "Loss: 0.9396225810050964 lr : 0.000001 \n",
      "Loss: 0.4866473972797394 lr : 0.000001 \n",
      "Loss: 0.528394341468811 lr : 0.000001 \n",
      "Loss: 0.5585935115814209 lr : 0.000001 \n",
      "Loss: 0.535507321357727 lr : 0.000001 \n",
      "Loss: 0.5950077176094055 lr : 0.000001 \n",
      "Loss: 1.1367534399032593 lr : 0.000001 \n",
      "Loss: 0.7144045233726501 lr : 0.000001 \n",
      "Loss: 0.5857048034667969 lr : 0.000001 \n",
      "Loss: 0.5799620747566223 lr : 0.000001 \n",
      "Loss: 0.8547692894935608 lr : 0.000001 \n",
      "Loss: 0.7709102034568787 lr : 0.000001 \n",
      "Loss: 1.5183980464935303 lr : 0.000001 \n",
      "Loss: 1.0793415307998657 lr : 0.000001 \n",
      "Loss: 1.383808970451355 lr : 0.000001 \n",
      "Loss: 0.741202175617218 lr : 0.000001 \n",
      "Loss: 1.3990885019302368 lr : 0.000001 \n",
      "Loss: 0.9306065440177917 lr : 0.000001 \n",
      "Loss: 1.1859210729599 lr : 0.000001 \n",
      "Loss: 1.3266493082046509 lr : 0.000001 \n",
      "Loss: 0.8522197008132935 lr : 0.000001 \n",
      "Loss: 0.9350834488868713 lr : 0.000001 \n",
      "Loss: 0.4463537931442261 lr : 0.000001 \n",
      "Loss: 0.8415548801422119 lr : 0.000001 \n",
      "Loss: 0.5649450421333313 lr : 0.000001 \n",
      "Loss: 0.7391598224639893 lr : 0.000001 \n",
      "Loss: 0.7470505833625793 lr : 0.000001 \n",
      "Loss: 4.536355845630169e-05 lr : 0.000001 \n",
      "Loss: 0.5886358618736267 lr : 0.000001 \n",
      "Loss: 0.7820354104042053 lr : 0.000001 \n",
      "Loss: 1.008583664894104 lr : 0.000001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2012428045272827 lr : 0.000001 \n",
      "Loss: 1.2473483085632324 lr : 0.000001 \n",
      "Loss: 0.2622053921222687 lr : 0.000001 \n",
      "Loss: 0.9974551796913147 lr : 0.000001 \n",
      "Loss: 0.5858674645423889 lr : 0.000001 \n",
      "Loss: 1.6607046127319336 lr : 0.000001 \n",
      "Loss: 1.1372934579849243 lr : 0.000001 \n",
      "Loss: 0.7832227945327759 lr : 0.000001 \n",
      "Loss: 0.571606457233429 lr : 0.000001 \n",
      "Loss: 0.6467158198356628 lr : 0.000001 \n",
      "Loss: 1.0601569414138794 lr : 0.000001 \n",
      "Loss: 0.6577380299568176 lr : 0.000001 \n",
      "Loss: 0.5495434999465942 lr : 0.000001 \n",
      "Loss: 0.8550590872764587 lr : 0.000001 \n",
      "Loss: 0.5401104688644409 lr : 0.000001 \n",
      "Loss: 0.9272490739822388 lr : 0.000001 \n",
      "Loss: 1.240848183631897 lr : 0.000001 \n",
      "Loss: 0.7225064039230347 lr : 0.000001 \n",
      "Loss: 0.9000689387321472 lr : 0.000001 \n",
      "Loss: 0.32082512974739075 lr : 0.000001 \n",
      "Loss: 0.3496215343475342 lr : 0.000001 \n",
      "Loss: 1.0830706357955933 lr : 0.000001 \n",
      "Loss: 0.2834169268608093 lr : 0.000001 \n",
      "Loss: 0.7999798059463501 lr : 0.000000 \n",
      "Loss: 0.8917604088783264 lr : 0.000000 \n",
      "Loss: 1.2107598781585693 lr : 0.000000 \n",
      "Loss: 0.9116454124450684 lr : 0.000000 \n",
      "Loss: 0.6523775458335876 lr : 0.000000 \n",
      "Loss: 0.8228103518486023 lr : 0.000000 \n",
      "Loss: 1.173782229423523 lr : 0.000000 \n",
      "Loss: 1.2116187810897827 lr : 0.000000 \n",
      "Loss: 1.1761651039123535 lr : 0.000000 \n",
      "Loss: 1.071061372756958 lr : 0.000000 \n",
      "Loss: 1.4569177627563477 lr : 0.000000 \n",
      "Loss: 0.5581811666488647 lr : 0.000000 \n",
      "Loss: 0.6364666223526001 lr : 0.000000 \n",
      "Loss: 0.48982149362564087 lr : 0.000000 \n",
      "Loss: 0.9416795969009399 lr : 0.000000 \n",
      "Loss: 0.5748739242553711 lr : 0.000000 \n",
      "Loss: 0.32864099740982056 lr : 0.000000 \n",
      "Loss: 1.351837396621704 lr : 0.000000 \n",
      "Loss: 0.937477707862854 lr : 0.000000 \n",
      "Loss: 0.6326292157173157 lr : 0.000000 \n",
      "Loss: 0.8287363648414612 lr : 0.000000 \n",
      "Loss: 0.8567518591880798 lr : 0.000000 \n",
      "Loss: 0.6436338424682617 lr : 0.000000 \n",
      "Loss: 0.8958828449249268 lr : 0.000000 \n",
      "Loss: 0.6118891835212708 lr : 0.000000 \n",
      "Loss: 1.3223971128463745 lr : 0.000000 \n",
      "Loss: 0.32451921701431274 lr : 0.000000 \n",
      "Loss: 0.6569588780403137 lr : 0.000000 \n",
      "Loss: 0.8823327422142029 lr : 0.000000 \n",
      "Loss: 0.332599401473999 lr : 0.000000 \n",
      "Loss: 0.7244320511817932 lr : 0.000000 \n",
      "Loss: 0.5396562218666077 lr : 0.000000 \n",
      "Loss: 1.1513822078704834 lr : 0.000000 \n",
      "Loss: 0.33806392550468445 lr : 0.000000 \n",
      "Loss: 0.6539216041564941 lr : 0.000000 \n",
      "Loss: 0.45821353793144226 lr : 0.000000 \n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a84e2ae0d9e42c49ae7ba95008a5d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8207643628120422 lr : 0.000000 \n",
      "Loss: 0.7596992254257202 lr : 0.000000 \n",
      "Loss: 0.6613786816596985 lr : 0.000000 \n",
      "Loss: 0.823258638381958 lr : 0.000000 \n",
      "Loss: 0.5922842025756836 lr : 0.000000 \n",
      "Loss: 0.7599189281463623 lr : 0.000000 \n",
      "Loss: 0.8797274827957153 lr : 0.000000 \n",
      "Loss: 0.18269093334674835 lr : 0.000000 \n",
      "Loss: 0.9406559467315674 lr : 0.000000 \n",
      "Loss: 0.4452696144580841 lr : 0.000000 \n",
      "Loss: 1.6097608804702759 lr : 0.000000 \n",
      "Loss: 0.5526441335678101 lr : 0.000000 \n",
      "Loss: 0.7699441909790039 lr : 0.000000 \n",
      "Loss: 0.30928170680999756 lr : 0.000000 \n",
      "Loss: 0.819677472114563 lr : 0.000000 \n",
      "Loss: 0.7497047781944275 lr : 0.000000 \n",
      "Loss: 0.7219527959823608 lr : 0.000000 \n",
      "Loss: 0.4240249991416931 lr : 0.000000 \n",
      "Loss: 1.3104164600372314 lr : 0.000000 \n",
      "Loss: 0.6524028182029724 lr : 0.000000 \n",
      "Loss: 0.6703131794929504 lr : 0.000000 \n",
      "Loss: 0.7009182572364807 lr : 0.000000 \n",
      "Loss: 0.17330695688724518 lr : 0.000000 \n",
      "Loss: 0.8128225207328796 lr : 0.000000 \n",
      "Loss: 0.05697162076830864 lr : 0.000000 \n",
      "Loss: 0.6153751611709595 lr : 0.000000 \n",
      "Loss: 1.240228533744812 lr : 0.000000 \n",
      "Loss: 1.3807610273361206 lr : 0.000000 \n",
      "Loss: 0.5254716873168945 lr : 0.000000 \n",
      "Loss: 1.5434610843658447 lr : 0.000000 \n",
      "Loss: 0.22161562740802765 lr : 0.000000 \n",
      "Loss: 0.8479971289634705 lr : 0.000000 \n",
      "Loss: 0.7057284116744995 lr : 0.000000 \n",
      "Loss: 0.6537035703659058 lr : 0.000000 \n",
      "Loss: 0.6097729206085205 lr : 0.000000 \n",
      "Loss: 0.581099808216095 lr : 0.000000 \n",
      "Loss: 0.6307495832443237 lr : 0.000000 \n",
      "Loss: 1.1295735836029053 lr : 0.000000 \n",
      "Loss: 0.727893054485321 lr : 0.000000 \n",
      "Loss: 0.8136446475982666 lr : 0.000000 \n",
      "Loss: 0.9732863306999207 lr : 0.000000 \n",
      "Loss: 0.4207926094532013 lr : 0.000000 \n",
      "Loss: 0.910270094871521 lr : 0.000000 \n",
      "Loss: 0.5815441608428955 lr : 0.000000 \n",
      "Loss: 0.6797904968261719 lr : 0.000000 \n",
      "Loss: 0.9175793528556824 lr : 0.000000 \n",
      "Loss: 0.40570947527885437 lr : 0.000000 \n",
      "Loss: 0.9457931518554688 lr : 0.000000 \n",
      "Loss: 0.8187944293022156 lr : 0.000000 \n",
      "Loss: 0.6033044457435608 lr : 0.000000 \n",
      "Loss: 0.8417523503303528 lr : 0.000000 \n",
      "Loss: 0.928226888179779 lr : 0.000000 \n",
      "Loss: 0.6544049382209778 lr : 0.000000 \n",
      "Loss: 1.0478516817092896 lr : 0.000000 \n",
      "Loss: 0.597407341003418 lr : 0.000000 \n",
      "Loss: 0.662175178527832 lr : 0.000000 \n",
      "Loss: 1.1713615655899048 lr : 0.000000 \n",
      "Loss: 0.5890758037567139 lr : 0.000000 \n",
      "Loss: 0.8802894949913025 lr : 0.000000 \n",
      "Loss: 0.48405319452285767 lr : 0.000000 \n",
      "Loss: 0.3534751534461975 lr : 0.000000 \n",
      "Loss: 0.9756286144256592 lr : 0.000000 \n",
      "Loss: 1.00497305393219 lr : 0.000000 \n",
      "Loss: 1.0439205169677734 lr : 0.000000 \n",
      "Loss: 1.080209493637085 lr : 0.000000 \n",
      "Loss: 0.29484525322914124 lr : 0.000000 \n",
      "Loss: 0.29819196462631226 lr : 0.000000 \n",
      "Loss: 0.7041445970535278 lr : 0.000000 \n",
      "Loss: 0.7885842323303223 lr : 0.000000 \n",
      "Loss: 0.685429036617279 lr : 0.000000 \n",
      "Loss: 1.1610174179077148 lr : 0.000000 \n",
      "Loss: 0.9745647311210632 lr : 0.000000 \n",
      "Loss: 0.7174111008644104 lr : 0.000000 \n",
      "Loss: 0.2863575518131256 lr : 0.000000 \n",
      "Loss: 0.45917561650276184 lr : 0.000000 \n",
      "Loss: 0.897152841091156 lr : 0.000000 \n",
      "Loss: 0.47655248641967773 lr : 0.000000 \n",
      "Loss: 0.28087088465690613 lr : 0.000000 \n",
      "Loss: 0.6303249001502991 lr : 0.000000 \n",
      "Loss: 1.0387507677078247 lr : 0.000000 \n",
      "Loss: 0.6448760628700256 lr : 0.000000 \n",
      "Loss: 1.2225247621536255 lr : 0.000000 \n",
      "Loss: 0.5125114917755127 lr : 0.000000 \n",
      "Loss: 0.5073871612548828 lr : 0.000000 \n",
      "Loss: 0.5524451732635498 lr : 0.000000 \n",
      "Loss: 0.5193154811859131 lr : 0.000000 \n",
      "Loss: 0.5137472748756409 lr : 0.000000 \n",
      "Loss: 1.063410997390747 lr : 0.000000 \n",
      "Loss: 0.9860934615135193 lr : 0.000000 \n",
      "Loss: 1.0073007345199585 lr : 0.000000 \n",
      "Loss: 0.726345419883728 lr : 0.000000 \n",
      "Loss: 1.1034280061721802 lr : 0.000000 \n",
      "Loss: 0.8695666193962097 lr : 0.000000 \n",
      "Loss: 1.1215546131134033 lr : 0.000000 \n",
      "Loss: 1.2819383144378662 lr : 0.000000 \n",
      "Loss: 0.33091166615486145 lr : 0.000000 \n",
      "Loss: 1.0472218990325928 lr : 0.000000 \n",
      "Loss: 1.241700530052185 lr : 0.000000 \n",
      "Loss: 0.929972767829895 lr : 0.000000 \n",
      "Loss: 0.306452214717865 lr : 0.000000 \n",
      "Loss: 0.8350082039833069 lr : 0.000000 \n",
      "Loss: 0.7352127432823181 lr : 0.000000 \n",
      "Loss: 0.6389915943145752 lr : 0.000000 \n",
      "Loss: 0.6695051193237305 lr : 0.000000 \n",
      "Loss: 0.16945520043373108 lr : 0.000000 \n",
      "Loss: 0.43471479415893555 lr : 0.000000 \n",
      "Loss: 0.8348921537399292 lr : 0.000000 \n",
      "Loss: 0.5812235474586487 lr : 0.000000 \n",
      "Loss: 0.29273954033851624 lr : 0.000000 \n",
      "Loss: 1.2126853466033936 lr : 0.000000 \n",
      "Loss: 1.0734002590179443 lr : 0.000000 \n",
      "Loss: 1.1369253396987915 lr : 0.000000 \n",
      "Loss: 0.24364051222801208 lr : 0.000000 \n",
      "Loss: 0.5523761510848999 lr : 0.000000 \n",
      "Loss: 0.33555132150650024 lr : 0.000000 \n",
      "Loss: 0.38772550225257874 lr : 0.000000 \n",
      "Loss: 0.4254268407821655 lr : 0.000000 \n",
      "Loss: 1.0650370121002197 lr : 0.000000 \n",
      "Loss: 0.5447708964347839 lr : 0.000000 \n",
      "Loss: 0.7692052125930786 lr : 0.000000 \n",
      "Loss: 0.5022470951080322 lr : 0.000000 \n",
      "Loss: 1.0911149978637695 lr : 0.000000 \n",
      "Loss: 0.7139361500740051 lr : 0.000000 \n",
      "Loss: 0.34822332859039307 lr : 0.000000 \n",
      "Loss: 0.4885551333427429 lr : 0.000000 \n",
      "Loss: 0.5003769397735596 lr : 0.000000 \n",
      "Loss: 0.8451215028762817 lr : 0.000000 \n",
      "Loss: 0.7808861136436462 lr : 0.000000 \n",
      "Loss: 0.9881234169006348 lr : 0.000000 \n",
      "Loss: 1.0749108791351318 lr : 0.000000 \n",
      "Loss: 1.3267605304718018 lr : 0.000000 \n",
      "Loss: 0.34271785616874695 lr : 0.000000 \n",
      "Loss: 0.8031864166259766 lr : 0.000000 \n",
      "Loss: 1.239043951034546 lr : 0.000000 \n",
      "Loss: 0.8386887311935425 lr : 0.000000 \n",
      "Loss: 1.131737232208252 lr : 0.000000 \n",
      "Loss: 0.36020877957344055 lr : 0.000000 \n",
      "Loss: 0.6300956606864929 lr : 0.000000 \n",
      "Loss: 0.6054743528366089 lr : 0.000000 \n",
      "Loss: 0.6466248035430908 lr : 0.000000 \n",
      "Loss: 0.4373847544193268 lr : 0.000000 \n",
      "Loss: 1.254879117012024 lr : 0.000000 \n",
      "Loss: 1.0326473712921143 lr : 0.000000 \n",
      "Loss: 1.7152122259140015 lr : 0.000000 \n",
      "Loss: 0.7527925968170166 lr : 0.000000 \n",
      "Loss: 0.5350550413131714 lr : 0.000000 \n",
      "Loss: 1.08917236328125 lr : 0.000000 \n",
      "Loss: 0.8097635507583618 lr : 0.000000 \n",
      "Loss: 0.7197374701499939 lr : 0.000000 \n",
      "Loss: 0.9971691966056824 lr : 0.000000 \n",
      "Loss: 0.7637940645217896 lr : 0.000000 \n",
      "Loss: 0.5996639728546143 lr : 0.000000 \n",
      "Loss: 0.13953270018100739 lr : 0.000000 \n",
      "Loss: 0.2474481612443924 lr : 0.000000 \n",
      "Loss: 1.1992627382278442 lr : 0.000000 \n",
      "Loss: 0.35187050700187683 lr : 0.000000 \n",
      "Loss: 1.1973235607147217 lr : 0.000000 \n",
      "Loss: 0.9093548059463501 lr : 0.000000 \n",
      "Loss: 0.6721939444541931 lr : 0.000000 \n",
      "Loss: 3.6664772778749466e-05 lr : 0.000000 \n",
      "Loss: 0.9080861806869507 lr : 0.000000 \n",
      "Loss: 0.41477519273757935 lr : 0.000000 \n",
      "Loss: 1.1872873306274414 lr : 0.000000 \n",
      "Loss: 0.7757112383842468 lr : 0.000000 \n",
      "Loss: 0.6576715111732483 lr : 0.000000 \n",
      "Loss: 0.5999805927276611 lr : 0.000000 \n",
      "Loss: 0.7311533093452454 lr : 0.000000 \n",
      "Loss: 0.30199724435806274 lr : 0.000000 \n",
      "Loss: 1.6118652820587158 lr : 0.000000 \n",
      "Loss: 0.8456433415412903 lr : 0.000000 \n",
      "Loss: 0.9988155961036682 lr : 0.000000 \n",
      "Loss: 0.596527099609375 lr : 0.000000 \n",
      "Loss: 1.0254976749420166 lr : 0.000000 \n",
      "Loss: 0.5095522999763489 lr : 0.000000 \n",
      "Loss: 0.7045459747314453 lr : 0.000000 \n",
      "Loss: 0.8952351212501526 lr : 0.000000 \n",
      "Loss: 0.8921995162963867 lr : 0.000000 \n",
      "Loss: 1.247228741645813 lr : 0.000000 \n",
      "Loss: 0.9915741086006165 lr : 0.000000 \n",
      "Loss: 0.5128952860832214 lr : 0.000000 \n",
      "Loss: 0.6538283824920654 lr : 0.000000 \n",
      "Loss: 0.170599102973938 lr : 0.000000 \n",
      "Loss: 0.8245067000389099 lr : 0.000000 \n",
      "Loss: 0.6793134808540344 lr : 0.000000 \n",
      "Loss: 1.1764274835586548 lr : 0.000000 \n",
      "Loss: 1.1316982507705688 lr : 0.000000 \n",
      "Loss: 0.9356138110160828 lr : 0.000000 \n",
      "Loss: 0.6420115828514099 lr : 0.000000 \n",
      "Loss: 1.260998010635376 lr : 0.000000 \n",
      "Loss: 0.9243280291557312 lr : 0.000000 \n",
      "Loss: 0.45990464091300964 lr : 0.000000 \n",
      "Loss: 0.8077062368392944 lr : 0.000000 \n",
      "Loss: 1.2572578191757202 lr : 0.000000 \n",
      "Loss: 0.6725982427597046 lr : 0.000000 \n",
      "Loss: 1.081165075302124 lr : 0.000000 \n",
      "Loss: 0.8570813536643982 lr : 0.000000 \n",
      "Loss: 0.462571918964386 lr : 0.000000 \n",
      "Loss: 0.7961355447769165 lr : 0.000000 \n",
      "Loss: 0.21213239431381226 lr : 0.000000 \n",
      "Loss: 0.6288480162620544 lr : 0.000000 \n",
      "Loss: 0.2566256523132324 lr : 0.000000 \n",
      "Loss: 0.32449400424957275 lr : 0.000000 \n",
      "Loss: 0.7116978764533997 lr : 0.000000 \n",
      "Loss: 0.9498840570449829 lr : 0.000000 \n",
      "Loss: 0.5433815121650696 lr : 0.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.692176342010498 lr : 0.000000 \n",
      "Loss: 0.34508681297302246 lr : 0.000000 \n",
      "Loss: 0.9469715356826782 lr : 0.000000 \n",
      "Loss: 0.7209911942481995 lr : 0.000000 \n",
      "Loss: 0.5152581334114075 lr : 0.000000 \n",
      "Loss: 0.7375945448875427 lr : 0.000000 \n",
      "Loss: 1.5237008333206177 lr : 0.000000 \n",
      "Loss: 0.5869733691215515 lr : 0.000000 \n",
      "Loss: 0.6620112657546997 lr : 0.000000 \n",
      "Loss: 0.8475804328918457 lr : 0.000000 \n",
      "Loss: 0.49475809931755066 lr : 0.000000 \n",
      "Loss: 0.7436007857322693 lr : 0.000000 \n",
      "Loss: 0.7389776706695557 lr : 0.000000 \n",
      "Loss: 0.8566256761550903 lr : 0.000000 \n",
      "Loss: 0.6119924783706665 lr : 0.000000 \n",
      "Loss: 1.3368879556655884 lr : 0.000000 \n",
      "Loss: 0.8153706789016724 lr : 0.000000 \n",
      "Loss: 0.2263103574514389 lr : 0.000000 \n",
      "Loss: 0.5985241532325745 lr : 0.000000 \n",
      "Loss: 0.6460602283477783 lr : 0.000000 \n",
      "Loss: 0.41680851578712463 lr : 0.000000 \n",
      "Loss: 1.072177529335022 lr : 0.000000 \n",
      "Loss: 0.9424703121185303 lr : 0.000000 \n",
      "Loss: 0.525698721408844 lr : 0.000000 \n",
      "Loss: 1.2016626596450806 lr : 0.000000 \n",
      "Loss: 1.0932834148406982 lr : 0.000000 \n",
      "Loss: 0.831589937210083 lr : 0.000000 \n",
      "Loss: 0.9517489671707153 lr : 0.000000 \n",
      "Loss: 0.8922829627990723 lr : 0.000000 \n",
      "Loss: 1.1640385389328003 lr : 0.000000 \n",
      "Loss: 0.6134495735168457 lr : 0.000000 \n",
      "Loss: 1.1557546854019165 lr : 0.000000 \n",
      "Loss: 0.6132851839065552 lr : 0.000000 \n",
      "Loss: 0.23221129179000854 lr : 0.000000 \n",
      "Loss: 0.6251840591430664 lr : 0.000000 \n",
      "Loss: 0.9633938074111938 lr : 0.000000 \n",
      "Loss: 0.7485181093215942 lr : 0.000000 \n",
      "Loss: 0.8021541237831116 lr : 0.000000 \n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079711adae614b60b886f48adb243a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6509323120117188 lr : 0.000000 \n",
      "Loss: 1.474658489227295 lr : 0.000000 \n",
      "Loss: 0.8113728761672974 lr : 0.000000 \n",
      "Loss: 0.43169093132019043 lr : 0.000000 \n",
      "Loss: 0.944196343421936 lr : 0.000000 \n",
      "Loss: 1.5682525634765625 lr : 0.000000 \n",
      "Loss: 0.452965646982193 lr : 0.000000 \n",
      "Loss: 1.1235264539718628 lr : 0.000000 \n",
      "Loss: 0.5490254759788513 lr : 0.000000 \n",
      "Loss: 0.18809176981449127 lr : 0.000000 \n",
      "Loss: 0.20429714024066925 lr : 0.000000 \n",
      "Loss: 0.7552458047866821 lr : 0.000000 \n",
      "Loss: 0.6732435822486877 lr : 0.000000 \n",
      "Loss: 0.3152370750904083 lr : 0.000000 \n",
      "Loss: 0.4704183042049408 lr : 0.000000 \n",
      "Loss: 0.9963559508323669 lr : 0.000000 \n",
      "Loss: 1.170369029045105 lr : 0.000000 \n",
      "Loss: 0.7466986775398254 lr : 0.000000 \n",
      "Loss: 0.8500944375991821 lr : 0.000000 \n",
      "Loss: 0.6573537588119507 lr : 0.000000 \n",
      "Loss: 0.7682428359985352 lr : 0.000000 \n",
      "Loss: 0.6529017686843872 lr : 0.000000 \n",
      "Loss: 1.7234169244766235 lr : 0.000000 \n",
      "Loss: 0.8686783909797668 lr : 0.000000 \n",
      "Loss: 1.2084954977035522 lr : 0.000000 \n",
      "Loss: 2.9460759833455086e-05 lr : 0.000000 \n",
      "Loss: 0.49051690101623535 lr : 0.000000 \n",
      "Loss: 0.8357011079788208 lr : 0.000000 \n",
      "Loss: 0.8141917586326599 lr : 0.000000 \n",
      "Loss: 0.5699871182441711 lr : 0.000000 \n",
      "Loss: 1.4857406616210938 lr : 0.000000 \n",
      "Loss: 0.8527981638908386 lr : 0.000000 \n",
      "Loss: 0.6789644360542297 lr : 0.000000 \n",
      "Loss: 1.0005816221237183 lr : 0.000000 \n",
      "Loss: 0.7474585771560669 lr : 0.000000 \n",
      "Loss: 1.058367371559143 lr : 0.000000 \n",
      "Loss: 0.4932834208011627 lr : 0.000000 \n",
      "Loss: 0.7459591031074524 lr : 0.000000 \n",
      "Loss: 0.7677923440933228 lr : 0.000000 \n",
      "Loss: 1.0939441919326782 lr : 0.000000 \n",
      "Loss: 1.506650686264038 lr : 0.000000 \n",
      "Loss: 0.720398485660553 lr : 0.000000 \n",
      "Loss: 0.7562841176986694 lr : 0.000000 \n",
      "Loss: 0.20093411207199097 lr : 0.000000 \n",
      "Loss: 0.8622468709945679 lr : 0.000000 \n",
      "Loss: 0.8782995939254761 lr : 0.000000 \n",
      "Loss: 0.3088046908378601 lr : 0.000000 \n",
      "Loss: 0.6995933651924133 lr : 0.000000 \n",
      "Loss: 1.4395751953125 lr : 0.000000 \n",
      "Loss: 0.7905234694480896 lr : 0.000000 \n",
      "Loss: 0.3659701943397522 lr : 0.000000 \n",
      "Loss: 0.8467409610748291 lr : 0.000000 \n",
      "Loss: 0.6506664156913757 lr : 0.000000 \n",
      "Loss: 1.0889906883239746 lr : 0.000000 \n",
      "Loss: 1.1311155557632446 lr : 0.000000 \n",
      "Loss: 0.5706048011779785 lr : 0.000000 \n",
      "Loss: 0.3464234471321106 lr : 0.000000 \n",
      "Loss: 1.1118707656860352 lr : 0.000000 \n",
      "Loss: 1.2181527614593506 lr : 0.000000 \n",
      "Loss: 0.3237625062465668 lr : 0.000000 \n",
      "Loss: 0.638978898525238 lr : 0.000000 \n",
      "Loss: 0.48465782403945923 lr : 0.000000 \n",
      "Loss: 0.7670829892158508 lr : 0.000000 \n",
      "Loss: 1.4510467052459717 lr : 0.000000 \n",
      "Loss: 0.3359141945838928 lr : 0.000000 \n",
      "Loss: 0.5503603219985962 lr : 0.000000 \n",
      "Loss: 0.5582057237625122 lr : 0.000000 \n",
      "Loss: 1.0710632801055908 lr : 0.000000 \n",
      "Loss: 0.2767469882965088 lr : 0.000000 \n",
      "Loss: 0.7704985737800598 lr : 0.000000 \n",
      "Loss: 0.22961220145225525 lr : 0.000000 \n",
      "Loss: 0.797149658203125 lr : 0.000000 \n",
      "Loss: 1.0591225624084473 lr : 0.000000 \n",
      "Loss: 0.8214146494865417 lr : 0.000000 \n",
      "Loss: 1.0200928449630737 lr : 0.000000 \n",
      "Loss: 1.0874005556106567 lr : 0.000000 \n",
      "Loss: 1.1040245294570923 lr : 0.000000 \n",
      "Loss: 0.8057190775871277 lr : 0.000000 \n",
      "Loss: 0.8692216873168945 lr : 0.000000 \n",
      "Loss: 0.8738420605659485 lr : 0.000000 \n",
      "Loss: 0.8057839274406433 lr : 0.000000 \n",
      "Loss: 0.8494910597801208 lr : 0.000000 \n",
      "Loss: 1.0258259773254395 lr : 0.000000 \n",
      "Loss: 0.5009295344352722 lr : 0.000000 \n",
      "Loss: 1.062528371810913 lr : 0.000000 \n",
      "Loss: 0.8259862661361694 lr : 0.000000 \n",
      "Loss: 0.3876776099205017 lr : 0.000000 \n",
      "Loss: 0.6109263896942139 lr : 0.000000 \n",
      "Loss: 1.1275389194488525 lr : 0.000000 \n",
      "Loss: 0.6073387861251831 lr : 0.000000 \n",
      "Loss: 0.713505208492279 lr : 0.000000 \n",
      "Loss: 0.9428029656410217 lr : 0.000000 \n",
      "Loss: 0.668269693851471 lr : 0.000000 \n",
      "Loss: 0.7815393209457397 lr : 0.000000 \n",
      "Loss: 0.890107274055481 lr : 0.000000 \n",
      "Loss: 0.833751380443573 lr : 0.000000 \n",
      "Loss: 0.8915737867355347 lr : 0.000000 \n",
      "Loss: 0.4582344889640808 lr : 0.000000 \n",
      "Loss: 0.6806003451347351 lr : 0.000000 \n",
      "Loss: 1.2215293645858765 lr : 0.000000 \n",
      "Loss: 0.2986209988594055 lr : 0.000000 \n",
      "Loss: 0.7464897036552429 lr : 0.000000 \n",
      "Loss: 0.5672075152397156 lr : 0.000000 \n",
      "Loss: 0.6024444103240967 lr : 0.000000 \n",
      "Loss: 0.6401540040969849 lr : 0.000000 \n",
      "Loss: 1.1237492561340332 lr : 0.000000 \n",
      "Loss: 0.677068829536438 lr : 0.000000 \n",
      "Loss: 1.5990904569625854 lr : 0.000000 \n",
      "Loss: 0.7951571345329285 lr : 0.000000 \n",
      "Loss: 0.9728240370750427 lr : 0.000000 \n",
      "Loss: 1.0523240566253662 lr : 0.000000 \n",
      "Loss: 0.28716734051704407 lr : 0.000000 \n",
      "Loss: 0.6321940422058105 lr : 0.000000 \n",
      "Loss: 0.2096460908651352 lr : 0.000000 \n",
      "Loss: 0.016144555062055588 lr : 0.000000 \n",
      "Loss: 0.3367786705493927 lr : 0.000000 \n",
      "Loss: 0.6057437658309937 lr : 0.000000 \n",
      "Loss: 0.6185330152511597 lr : 0.000000 \n",
      "Loss: 1.3410483598709106 lr : 0.000000 \n",
      "Loss: 0.676908552646637 lr : 0.000000 \n",
      "Loss: 0.7639800906181335 lr : 0.000000 \n",
      "Loss: 0.6089000105857849 lr : 0.000000 \n",
      "Loss: 0.8518275022506714 lr : 0.000000 \n",
      "Loss: 0.6164224147796631 lr : 0.000000 \n",
      "Loss: 0.8404784202575684 lr : 0.000000 \n",
      "Loss: 0.42106443643569946 lr : 0.000000 \n",
      "Loss: 0.7334434390068054 lr : 0.000000 \n",
      "Loss: 0.8767035603523254 lr : 0.000000 \n",
      "Loss: 1.0527174472808838 lr : 0.000000 \n",
      "Loss: 0.5832234621047974 lr : 0.000000 \n",
      "Loss: 0.7355763912200928 lr : 0.000000 \n",
      "Loss: 1.1028650999069214 lr : 0.000000 \n",
      "Loss: 1.064622402191162 lr : 0.000000 \n",
      "Loss: 0.7142974734306335 lr : 0.000000 \n",
      "Loss: 0.7106303572654724 lr : 0.000000 \n",
      "Loss: 0.8576464056968689 lr : 0.000000 \n",
      "Loss: 0.32688814401626587 lr : 0.000000 \n",
      "Loss: 0.6192089319229126 lr : 0.000000 \n",
      "Loss: 0.857566773891449 lr : 0.000000 \n",
      "Loss: 1.0632401704788208 lr : 0.000000 \n",
      "Loss: 0.8625408411026001 lr : 0.000000 \n",
      "Loss: 1.1571048498153687 lr : 0.000000 \n",
      "Loss: 0.6302375197410583 lr : 0.000000 \n",
      "Loss: 1.0185426473617554 lr : 0.000000 \n",
      "Loss: 0.5045965909957886 lr : 0.000000 \n",
      "Loss: 0.8202757835388184 lr : 0.000000 \n",
      "Loss: 0.5810603499412537 lr : 0.000000 \n",
      "Loss: 0.6460862159729004 lr : 0.000000 \n",
      "Loss: 0.674727201461792 lr : 0.000000 \n",
      "Loss: 1.0177147388458252 lr : 0.000000 \n",
      "Loss: 0.7082669734954834 lr : 0.000000 \n",
      "Loss: 0.32670465111732483 lr : 0.000000 \n",
      "Loss: 0.4181552827358246 lr : 0.000000 \n",
      "Loss: 0.7518371939659119 lr : 0.000000 \n",
      "Loss: 0.32508838176727295 lr : 0.000000 \n",
      "Loss: 0.6628401875495911 lr : 0.000000 \n",
      "Loss: 0.4977192282676697 lr : 0.000000 \n",
      "Loss: 1.2314074039459229 lr : 0.000000 \n",
      "Loss: 0.8987230062484741 lr : 0.000000 \n",
      "Loss: 0.677031397819519 lr : 0.000000 \n",
      "Loss: 0.6885591149330139 lr : 0.000000 \n",
      "Loss: 0.8964675664901733 lr : 0.000000 \n",
      "Loss: 1.0171900987625122 lr : 0.000000 \n",
      "Loss: 0.6658921241760254 lr : 0.000000 \n",
      "Loss: 1.2228745222091675 lr : 0.000000 \n",
      "Loss: 0.8315287828445435 lr : 0.000000 \n",
      "Loss: 1.3200080394744873 lr : 0.000000 \n",
      "Loss: 0.9879582524299622 lr : 0.000000 \n",
      "Loss: 0.8668639063835144 lr : 0.000000 \n",
      "Loss: 0.9266022443771362 lr : 0.000000 \n",
      "Loss: 1.035218358039856 lr : 0.000000 \n",
      "Loss: 0.6491984724998474 lr : 0.000000 \n",
      "Loss: 0.9930077195167542 lr : 0.000000 \n",
      "Loss: 0.8946071863174438 lr : 0.000000 \n",
      "Loss: 0.6926478147506714 lr : 0.000000 \n",
      "Loss: 0.7784616947174072 lr : 0.000000 \n",
      "Loss: 1.187145709991455 lr : 0.000000 \n",
      "Loss: 1.0349229574203491 lr : 0.000000 \n",
      "Loss: 1.0627743005752563 lr : 0.000000 \n",
      "Loss: 0.7634079456329346 lr : 0.000000 \n",
      "Loss: 0.4868256151676178 lr : 0.000000 \n",
      "Loss: 0.4153774082660675 lr : 0.000000 \n",
      "Loss: 0.5547387003898621 lr : 0.000000 \n",
      "Loss: 1.254733920097351 lr : 0.000000 \n",
      "Loss: 1.0423485040664673 lr : 0.000000 \n",
      "Loss: 0.6698125004768372 lr : 0.000000 \n",
      "Loss: 0.8116790652275085 lr : 0.000000 \n",
      "Loss: 0.3375067710876465 lr : 0.000000 \n",
      "Loss: 0.8519577980041504 lr : 0.000000 \n",
      "Loss: 1.1530247926712036 lr : 0.000000 \n",
      "Loss: 0.6135249137878418 lr : 0.000000 \n",
      "Loss: 0.6542419195175171 lr : 0.000000 \n",
      "Loss: 0.5433390140533447 lr : 0.000000 \n",
      "Loss: 1.2110285758972168 lr : 0.000000 \n",
      "Loss: 0.5866113305091858 lr : 0.000000 \n",
      "Loss: 0.6309052109718323 lr : 0.000000 \n",
      "Loss: 0.5332437753677368 lr : 0.000000 \n",
      "Loss: 0.8999868035316467 lr : 0.000000 \n",
      "Loss: 0.8237077593803406 lr : 0.000000 \n",
      "Loss: 0.8189536929130554 lr : 0.000000 \n",
      "Loss: 0.9630719423294067 lr : 0.000000 \n",
      "Loss: 1.2482597827911377 lr : 0.000000 \n",
      "Loss: 0.510444700717926 lr : 0.000000 \n",
      "Loss: 0.941628098487854 lr : 0.000000 \n",
      "Loss: 0.9819880127906799 lr : 0.000000 \n",
      "Loss: 0.4130447208881378 lr : 0.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8514475226402283 lr : 0.000000 \n",
      "Loss: 1.293064832687378 lr : 0.000000 \n",
      "Loss: 1.0143225193023682 lr : 0.000000 \n",
      "Loss: 1.0422883033752441 lr : 0.000000 \n",
      "Loss: 1.2476650476455688 lr : 0.000000 \n",
      "Loss: 0.24910324811935425 lr : 0.000000 \n",
      "Loss: 0.7972142696380615 lr : 0.000000 \n",
      "Loss: 1.1901086568832397 lr : 0.000000 \n",
      "Loss: 0.42412322759628296 lr : 0.000000 \n",
      "Loss: 1.1317559480667114 lr : 0.000000 \n",
      "Loss: 0.6861850619316101 lr : 0.000000 \n",
      "Loss: 0.39656612277030945 lr : 0.000000 \n",
      "Loss: 0.8621700406074524 lr : 0.000000 \n",
      "Loss: 0.7056178450584412 lr : 0.000000 \n",
      "Loss: 0.9518454074859619 lr : 0.000000 \n",
      "Loss: 0.9984250664710999 lr : 0.000000 \n",
      "Loss: 0.5631944537162781 lr : 0.000000 \n",
      "Loss: 0.777550458908081 lr : 0.000000 \n",
      "Loss: 0.31235307455062866 lr : 0.000000 \n",
      "Loss: 0.9698060750961304 lr : 0.000000 \n",
      "Loss: 0.6368464231491089 lr : 0.000000 \n",
      "Loss: 0.47314193844795227 lr : 0.000000 \n",
      "Loss: 0.7375641465187073 lr : 0.000000 \n",
      "Loss: 0.8368582725524902 lr : 0.000000 \n",
      "Loss: 0.2975318729877472 lr : 0.000000 \n",
      "Loss: 0.5543136596679688 lr : 0.000000 \n",
      "Loss: 0.5947991013526917 lr : 0.000000 \n",
      "Loss: 1.2440741062164307 lr : 0.000000 \n",
      "Loss: 0.559050440788269 lr : 0.000000 \n",
      "Loss: 0.14608296751976013 lr : 0.000000 \n",
      "Loss: 0.49076104164123535 lr : 0.000000 \n",
      "Loss: 0.3852759599685669 lr : 0.000000 \n",
      "Loss: 1.0606595277786255 lr : 0.000000 \n",
      "Loss: 0.6858793497085571 lr : 0.000000 \n",
      "Loss: 1.2340166568756104 lr : 0.000000 \n",
      "Loss: 1.6066361665725708 lr : 0.000000 \n",
      "Loss: 0.7044799327850342 lr : 0.000000 \n",
      "Epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f691d3f22e046df8635918aa3d1a765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.822554886341095 lr : 0.000000 \n",
      "Loss: 1.1946192979812622 lr : 0.000000 \n",
      "Loss: 0.8359084725379944 lr : 0.000000 \n",
      "Loss: 0.6560397148132324 lr : 0.000000 \n",
      "Loss: 0.8776852488517761 lr : 0.000000 \n",
      "Loss: 0.635638952255249 lr : 0.000000 \n",
      "Loss: 0.6803064942359924 lr : 0.000000 \n",
      "Loss: 0.6456636190414429 lr : 0.000000 \n",
      "Loss: 0.792097806930542 lr : 0.000000 \n",
      "Loss: 0.6495094895362854 lr : 0.000000 \n",
      "Loss: 0.33406782150268555 lr : 0.000000 \n",
      "Loss: 0.8484772443771362 lr : 0.000000 \n",
      "Loss: 0.6731852293014526 lr : 0.000000 \n",
      "Loss: 0.8136777877807617 lr : 0.000000 \n",
      "Loss: 0.24912846088409424 lr : 0.000000 \n",
      "Loss: 1.0719871520996094 lr : 0.000000 \n",
      "Loss: 0.6304479837417603 lr : 0.000000 \n",
      "Loss: 0.7944542169570923 lr : 0.000000 \n",
      "Loss: 1.0570679903030396 lr : 0.000000 \n",
      "Loss: 1.469242811203003 lr : 0.000000 \n",
      "Loss: 0.15994170308113098 lr : 0.000000 \n",
      "Loss: 0.8354843258857727 lr : 0.000000 \n",
      "Loss: 1.0803004503250122 lr : 0.000000 \n",
      "Loss: 0.3736814856529236 lr : 0.000000 \n",
      "Loss: 0.4584267735481262 lr : 0.000000 \n",
      "Loss: 0.658625602722168 lr : 0.000000 \n",
      "Loss: 0.7430975437164307 lr : 0.000000 \n",
      "Loss: 0.5784240365028381 lr : 0.000000 \n",
      "Loss: 0.8431779742240906 lr : 0.000000 \n",
      "Loss: 0.6558236479759216 lr : 0.000000 \n",
      "Loss: 0.6542123556137085 lr : 0.000000 \n",
      "Loss: 0.6171281933784485 lr : 0.000000 \n",
      "Loss: 1.2048896551132202 lr : 0.000000 \n",
      "Loss: 1.5338118076324463 lr : 0.000000 \n",
      "Loss: 0.6329439878463745 lr : 0.000000 \n",
      "Loss: 0.5316298604011536 lr : 0.000000 \n",
      "Loss: 0.7163933515548706 lr : 0.000001 \n",
      "Loss: 0.7233519554138184 lr : 0.000001 \n",
      "Loss: 1.0847959518432617 lr : 0.000001 \n",
      "Loss: 0.5356191992759705 lr : 0.000001 \n",
      "Loss: 0.7553849816322327 lr : 0.000001 \n",
      "Loss: 0.5798351764678955 lr : 0.000001 \n",
      "Loss: 0.4327012300491333 lr : 0.000001 \n",
      "Loss: 0.5032769441604614 lr : 0.000001 \n",
      "Loss: 0.8294214010238647 lr : 0.000001 \n",
      "Loss: 1.2247909307479858 lr : 0.000001 \n",
      "Loss: 0.7588360905647278 lr : 0.000001 \n",
      "Loss: 0.852683424949646 lr : 0.000001 \n",
      "Loss: 0.7681398391723633 lr : 0.000001 \n",
      "Loss: 0.5684568881988525 lr : 0.000001 \n",
      "Loss: 0.48283159732818604 lr : 0.000001 \n",
      "Loss: 0.50480717420578 lr : 0.000001 \n",
      "Loss: 1.0475783348083496 lr : 0.000001 \n",
      "Loss: 0.33053112030029297 lr : 0.000001 \n",
      "Loss: 0.46588924527168274 lr : 0.000001 \n",
      "Loss: 0.9497178196907043 lr : 0.000001 \n",
      "Loss: 1.056824803352356 lr : 0.000001 \n",
      "Loss: 0.8637856841087341 lr : 0.000001 \n",
      "Loss: 0.4198779761791229 lr : 0.000001 \n",
      "Loss: 0.6391273140907288 lr : 0.000001 \n",
      "Loss: 0.8444075584411621 lr : 0.000001 \n",
      "Loss: 8.59785359352827e-06 lr : 0.000001 \n",
      "Loss: 0.3857923448085785 lr : 0.000001 \n",
      "Loss: 0.339813232421875 lr : 0.000001 \n",
      "Loss: 0.5374326705932617 lr : 0.000001 \n",
      "Loss: 1.4777333736419678 lr : 0.000001 \n",
      "Loss: 0.8976426720619202 lr : 0.000001 \n",
      "Loss: 0.3250890374183655 lr : 0.000001 \n",
      "Loss: 0.36691272258758545 lr : 0.000001 \n",
      "Loss: 1.220727562904358 lr : 0.000001 \n",
      "Loss: 0.8841885328292847 lr : 0.000001 \n",
      "Loss: 0.48848453164100647 lr : 0.000001 \n",
      "Loss: 0.7062381505966187 lr : 0.000001 \n",
      "Loss: 0.7395317554473877 lr : 0.000001 \n",
      "Loss: 1.5265430212020874 lr : 0.000001 \n",
      "Loss: 0.7184491753578186 lr : 0.000001 \n",
      "Loss: 0.8275277018547058 lr : 0.000001 \n",
      "Loss: 0.6585915088653564 lr : 0.000001 \n",
      "Loss: 1.1612566709518433 lr : 0.000001 \n",
      "Loss: 1.2184911966323853 lr : 0.000001 \n",
      "Loss: 0.7259804606437683 lr : 0.000001 \n",
      "Loss: 0.8151854276657104 lr : 0.000001 \n",
      "Loss: 0.8337993025779724 lr : 0.000001 \n",
      "Loss: 1.2807104587554932 lr : 0.000001 \n",
      "Loss: 0.8583018779754639 lr : 0.000001 \n",
      "Loss: 0.8651745319366455 lr : 0.000001 \n",
      "Loss: 0.5996191501617432 lr : 0.000001 \n",
      "Loss: 1.339385747909546 lr : 0.000001 \n",
      "Loss: 0.24087828397750854 lr : 0.000001 \n",
      "Loss: 0.09422489255666733 lr : 0.000001 \n",
      "Loss: 0.6700626611709595 lr : 0.000001 \n",
      "Loss: 0.31176823377609253 lr : 0.000001 \n",
      "Loss: 0.7947646379470825 lr : 0.000001 \n",
      "Loss: 0.29641491174697876 lr : 0.000001 \n",
      "Loss: 0.32485952973365784 lr : 0.000001 \n",
      "Loss: 0.7632344961166382 lr : 0.000001 \n",
      "Loss: 0.6937541365623474 lr : 0.000001 \n",
      "Loss: 0.7802219390869141 lr : 0.000001 \n",
      "Loss: 1.099636435508728 lr : 0.000001 \n",
      "Loss: 0.18295784294605255 lr : 0.000001 \n",
      "Loss: 1.1178886890411377 lr : 0.000001 \n",
      "Loss: 0.7935584187507629 lr : 0.000001 \n",
      "Loss: 1.1217809915542603 lr : 0.000001 \n",
      "Loss: 0.6618510484695435 lr : 0.000001 \n",
      "Loss: 1.3218986988067627 lr : 0.000001 \n",
      "Loss: 0.8760300278663635 lr : 0.000001 \n",
      "Loss: 0.5591748356819153 lr : 0.000001 \n",
      "Loss: 1.0714985132217407 lr : 0.000001 \n",
      "Loss: 0.8748632073402405 lr : 0.000001 \n",
      "Loss: 0.8570520877838135 lr : 0.000001 \n",
      "Loss: 0.3053048849105835 lr : 0.000001 \n",
      "Loss: 0.9493725299835205 lr : 0.000001 \n",
      "Loss: 0.6658409833908081 lr : 0.000001 \n",
      "Loss: 0.5813087821006775 lr : 0.000001 \n",
      "Loss: 0.673841118812561 lr : 0.000001 \n",
      "Loss: 0.5383179187774658 lr : 0.000001 \n",
      "Loss: 1.5642272233963013 lr : 0.000001 \n",
      "Loss: 0.7062863707542419 lr : 0.000001 \n",
      "Loss: 0.7255024909973145 lr : 0.000001 \n",
      "Loss: 0.7869744300842285 lr : 0.000001 \n",
      "Loss: 0.5367097854614258 lr : 0.000001 \n",
      "Loss: 0.5837199687957764 lr : 0.000001 \n",
      "Loss: 1.2607202529907227 lr : 0.000001 \n",
      "Loss: 0.7857576012611389 lr : 0.000001 \n",
      "Loss: 0.761918306350708 lr : 0.000001 \n",
      "Loss: 0.7235957980155945 lr : 0.000001 \n",
      "Loss: 0.7518357634544373 lr : 0.000001 \n",
      "Loss: 0.4694034159183502 lr : 0.000001 \n",
      "Loss: 1.0826568603515625 lr : 0.000001 \n",
      "Loss: 0.1872665137052536 lr : 0.000001 \n",
      "Loss: 0.7246479988098145 lr : 0.000001 \n",
      "Loss: 1.2998567819595337 lr : 0.000001 \n",
      "Loss: 0.5316287279129028 lr : 0.000001 \n",
      "Loss: 0.7745846509933472 lr : 0.000001 \n",
      "Loss: 0.6749424934387207 lr : 0.000001 \n",
      "Loss: 0.627716600894928 lr : 0.000001 \n",
      "Loss: 1.0021902322769165 lr : 0.000001 \n",
      "Loss: 0.9983346462249756 lr : 0.000001 \n",
      "Loss: 0.0019307185430079699 lr : 0.000001 \n",
      "Loss: 0.9333671927452087 lr : 0.000001 \n",
      "Loss: 1.0522774457931519 lr : 0.000001 \n",
      "Loss: 0.6023553609848022 lr : 0.000001 \n",
      "Loss: 0.49203935265541077 lr : 0.000001 \n",
      "Loss: 0.6640657782554626 lr : 0.000001 \n",
      "Loss: 0.44559183716773987 lr : 0.000001 \n",
      "Loss: 0.7155247926712036 lr : 0.000001 \n",
      "Loss: 0.5264903903007507 lr : 0.000001 \n",
      "Loss: 0.4278106391429901 lr : 0.000001 \n",
      "Loss: 0.7363951206207275 lr : 0.000001 \n",
      "Loss: 0.47763535380363464 lr : 0.000001 \n",
      "Loss: 1.0146970748901367 lr : 0.000001 \n",
      "Loss: 0.6849708557128906 lr : 0.000001 \n",
      "Loss: 0.486564964056015 lr : 0.000001 \n",
      "Loss: 1.056530237197876 lr : 0.000001 \n",
      "Loss: 0.8030871152877808 lr : 0.000001 \n",
      "Loss: 0.6707494258880615 lr : 0.000001 \n",
      "Loss: 0.7139713168144226 lr : 0.000001 \n",
      "Loss: 0.7854699492454529 lr : 0.000001 \n",
      "Loss: 0.42411866784095764 lr : 0.000001 \n",
      "Loss: 0.4929022192955017 lr : 0.000001 \n",
      "Loss: 0.8667991757392883 lr : 0.000001 \n",
      "Loss: 0.5436951518058777 lr : 0.000001 \n",
      "Loss: 1.1033421754837036 lr : 0.000001 \n",
      "Loss: 1.4733433723449707 lr : 0.000001 \n",
      "Loss: 0.4248763620853424 lr : 0.000001 \n",
      "Loss: 0.7728244066238403 lr : 0.000001 \n",
      "Loss: 0.3509790003299713 lr : 0.000001 \n",
      "Loss: 0.7016768455505371 lr : 0.000001 \n",
      "Loss: 0.0007734789978712797 lr : 0.000001 \n",
      "Loss: 0.4967268705368042 lr : 0.000001 \n",
      "Loss: 0.5402739644050598 lr : 0.000001 \n",
      "Loss: 0.5927493572235107 lr : 0.000001 \n",
      "Loss: 0.6657454967498779 lr : 0.000001 \n",
      "Loss: 0.8557636141777039 lr : 0.000001 \n",
      "Loss: 0.7012938261032104 lr : 0.000001 \n",
      "Loss: 0.7743154764175415 lr : 0.000001 \n",
      "Loss: 1.0603199005126953 lr : 0.000001 \n",
      "Loss: 0.9386188983917236 lr : 0.000001 \n",
      "Loss: 0.6592350006103516 lr : 0.000001 \n",
      "Loss: 0.17506428062915802 lr : 0.000001 \n",
      "Loss: 0.5973190069198608 lr : 0.000001 \n",
      "Loss: 1.211449384689331 lr : 0.000001 \n",
      "Loss: 1.0076146125793457 lr : 0.000001 \n",
      "Loss: 0.9959132075309753 lr : 0.000001 \n",
      "Loss: 0.5955033898353577 lr : 0.000001 \n",
      "Loss: 0.61234050989151 lr : 0.000001 \n",
      "Loss: 1.201227068901062 lr : 0.000001 \n",
      "Loss: 0.6289674639701843 lr : 0.000001 \n",
      "Loss: 1.0052237510681152 lr : 0.000001 \n",
      "Loss: 0.30567702651023865 lr : 0.000001 \n",
      "Loss: 1.2260891199111938 lr : 0.000001 \n",
      "Loss: 0.4958650767803192 lr : 0.000001 \n",
      "Loss: 0.5549906492233276 lr : 0.000001 \n",
      "Loss: 0.8329280018806458 lr : 0.000001 \n",
      "Loss: 0.3373628854751587 lr : 0.000001 \n",
      "Loss: 0.7512839436531067 lr : 0.000001 \n",
      "Loss: 1.043065071105957 lr : 0.000001 \n",
      "Loss: 0.8063269257545471 lr : 0.000001 \n",
      "Loss: 0.6786292195320129 lr : 0.000001 \n",
      "Loss: 0.3187016546726227 lr : 0.000001 \n",
      "Loss: 0.967626690864563 lr : 0.000001 \n",
      "Loss: 0.7758164405822754 lr : 0.000001 \n",
      "Loss: 0.31490105390548706 lr : 0.000001 \n",
      "Loss: 0.706551194190979 lr : 0.000001 \n",
      "Loss: 0.5711165070533752 lr : 0.000001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.26986783742904663 lr : 0.000001 \n",
      "Loss: 0.7213385105133057 lr : 0.000001 \n",
      "Loss: 1.2187060117721558 lr : 0.000001 \n",
      "Loss: 0.7964249849319458 lr : 0.000001 \n",
      "Loss: 0.6108760237693787 lr : 0.000001 \n",
      "Loss: 0.7462961077690125 lr : 0.000001 \n",
      "Loss: 0.7796894907951355 lr : 0.000001 \n",
      "Loss: 1.0889841318130493 lr : 0.000001 \n",
      "Loss: 0.2672808766365051 lr : 0.000001 \n",
      "Loss: 0.35482853651046753 lr : 0.000001 \n",
      "Loss: 0.9952284097671509 lr : 0.000001 \n",
      "Loss: 1.1094893217086792 lr : 0.000001 \n",
      "Loss: 0.2425563782453537 lr : 0.000001 \n",
      "Loss: 1.1115297079086304 lr : 0.000001 \n",
      "Loss: 1.2193368673324585 lr : 0.000001 \n",
      "Loss: 1.014015555381775 lr : 0.000001 \n",
      "Loss: 0.7908509373664856 lr : 0.000001 \n",
      "Loss: 1.1475123167037964 lr : 0.000001 \n",
      "Loss: 0.6541234254837036 lr : 0.000001 \n",
      "Loss: 1.2704393863677979 lr : 0.000001 \n",
      "Loss: 0.9871131777763367 lr : 0.000001 \n",
      "Loss: 0.9672818183898926 lr : 0.000001 \n",
      "Loss: 0.6557827591896057 lr : 0.000001 \n",
      "Loss: 1.2765076160430908 lr : 0.000001 \n",
      "Loss: 0.8192527890205383 lr : 0.000001 \n",
      "Loss: 1.1380759477615356 lr : 0.000001 \n",
      "Loss: 0.676906406879425 lr : 0.000001 \n",
      "Loss: 0.7660849690437317 lr : 0.000001 \n",
      "Loss: 1.0329477787017822 lr : 0.000001 \n",
      "Loss: 0.739726185798645 lr : 0.000001 \n",
      "Loss: 0.6465830206871033 lr : 0.000001 \n",
      "Loss: 0.5527886748313904 lr : 0.000001 \n",
      "Loss: 1.381615400314331 lr : 0.000001 \n",
      "Loss: 0.324766606092453 lr : 0.000001 \n",
      "Loss: 0.5350723266601562 lr : 0.000001 \n",
      "Loss: 0.9766619205474854 lr : 0.000001 \n",
      "Loss: 0.7031388282775879 lr : 0.000001 \n",
      "Loss: 0.7413952946662903 lr : 0.000001 \n"
     ]
    }
   ],
   "source": [
    "loss_file = open(\"loss.txt\",\"w\")\n",
    "\n",
    "for epoch in range(CFG.epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for idx, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        labels = batch.pop(\"labels\").to(device)\n",
    "        flattened_patches = batch.pop(\"flattened_patches\").to(device)\n",
    "        attention_mask = batch.pop(\"attention_mask\").to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(flattened_patches=flattened_patches,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        #grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1000)\n",
    "        # Unscales gradients and calls\n",
    "        # or skips optimizer.step()\n",
    "        scaler.step(optimizer)\n",
    "        # Updates the scale for next iteration\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        if idx % 100 == 0:\n",
    "            print(\"Loss:\", loss.item(), f'lr : {scheduler.get_lr()[0]:.6f} ', sep=' ')\n",
    "            loss_file.write(f\"Epoch: {epoch}, Iteration: {idx}, Loss: {loss.item()}\\n\")\n",
    "            loss_file.flush()\n",
    "        \n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        torch.save(model.state_dict(), f'./matcha_v1/matcha_{epoch}.bin')\n",
    "\n",
    "loss_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "023b5038cdf34f7f96f295311001d78d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_472f6d8ee41443a0a82993c72ae6fe40",
       "IPY_MODEL_f342d35498a345f1991a5afc0a0edbca",
       "IPY_MODEL_9565dc8405bb4a5fb2850fc1e12fdd92"
      ],
      "layout": "IPY_MODEL_5e1878670f1f446085b14a37e9072a95"
     }
    },
    "0b5dbbba4bb9497c9ad9d83d4a9fcc3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c162151952d4b04a764ed1999e6c46b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2711948ea2b64c3ea58b535dccbc8d41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2829b790c46d4e05983d501f910ed7f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28ba10dfff154193a8bfb648e7fca4c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a91ec7117534897ab30f096de821816": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cab1d494c454a1abfca420484d952f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7177fa27755e4249a12444cc885c7abe",
      "placeholder": "​",
      "style": "IPY_MODEL_cf6e28052907414ab3f98c1f45672d29",
      "value": " 89%"
     }
    },
    "309537918947492d8c771b8b20aef21e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a9c8776be924bf18b639dc76f72ca8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "472f6d8ee41443a0a82993c72ae6fe40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a6f464a1ffa4cc49b634da46809e681",
      "placeholder": "​",
      "style": "IPY_MODEL_e203a6f9f2c1430582f060a9ea71c57e",
      "value": "100%"
     }
    },
    "47c8e38fe9d24f6b824acf7e4f1c3ce6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbbc074448f740f99b37e456752a67e6",
       "IPY_MODEL_e4c9e1a41cbc4b86a249fee581c9175e",
       "IPY_MODEL_4f3f0a98f5834f0d85b11265e9b795e4"
      ],
      "layout": "IPY_MODEL_5a8622ee44f54015b58155a6a8a6cbcd"
     }
    },
    "4ee2ed07ef4b4a87be35ba7fef8ace72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f3f0a98f5834f0d85b11265e9b795e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7f912192edf4cdcbdd8154b712faf84",
      "placeholder": "​",
      "style": "IPY_MODEL_2a91ec7117534897ab30f096de821816",
      "value": " 4846/4846 [1:13:19&lt;00:00,  1.33it/s]"
     }
    },
    "57fb5d24963d4b3fbeb8d5dd7652effd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b5dbbba4bb9497c9ad9d83d4a9fcc3c",
      "placeholder": "​",
      "style": "IPY_MODEL_8fba95ad2bf64da1b6694b542b164182",
      "value": " 60568/60568 [00:45&lt;00:00, 1470.84it/s]"
     }
    },
    "5a8622ee44f54015b58155a6a8a6cbcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1878670f1f446085b14a37e9072a95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7177fa27755e4249a12444cc885c7abe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a6f464a1ffa4cc49b634da46809e681": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "861b9397d0d4498688ee54ff22b613ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8fba95ad2bf64da1b6694b542b164182": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9565dc8405bb4a5fb2850fc1e12fdd92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6ff9c8e096b4cb48c239610131b8bb7",
      "placeholder": "​",
      "style": "IPY_MODEL_ca383499f23640b38d7e8701d3daea32",
      "value": " 4846/4846 [1:13:28&lt;00:00,  1.33it/s]"
     }
    },
    "987333f84cdb4dfca94e41e1b6b2246e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f21445de34624b6e92a86a4fc470c71f",
      "placeholder": "​",
      "style": "IPY_MODEL_1c162151952d4b04a764ed1999e6c46b",
      "value": " 4323/4846 [1:05:26&lt;07:54,  1.10it/s]"
     }
    },
    "9aca2f8e1f6644eebddb205ea4a5e0c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a62f1a1670b34720a640c221f1b8d0f1",
      "max": 4846,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba63637b809d43aa809cb8c81c8a9d65",
      "value": 4323
     }
    },
    "a62f1a1670b34720a640c221f1b8d0f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b26d75d84741429fa34441fec197307f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3fb82ffd89c469386597033679e2440": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ee2ed07ef4b4a87be35ba7fef8ace72",
      "max": 60568,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f843c915c5e042e5ac3f5ab6c45572d8",
      "value": 60568
     }
    },
    "b6ff9c8e096b4cb48c239610131b8bb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba63637b809d43aa809cb8c81c8a9d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bea712bc9a3a483a970562697d153938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2711948ea2b64c3ea58b535dccbc8d41",
      "placeholder": "​",
      "style": "IPY_MODEL_861b9397d0d4498688ee54ff22b613ce",
      "value": "100%"
     }
    },
    "bfd555e3be014b42ae3120e7e4d0b903": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bea712bc9a3a483a970562697d153938",
       "IPY_MODEL_b3fb82ffd89c469386597033679e2440",
       "IPY_MODEL_57fb5d24963d4b3fbeb8d5dd7652effd"
      ],
      "layout": "IPY_MODEL_3a9c8776be924bf18b639dc76f72ca8f"
     }
    },
    "ca383499f23640b38d7e8701d3daea32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf6e28052907414ab3f98c1f45672d29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d158c3785b5c4b13a9024a0d3e1c0ef2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7f912192edf4cdcbdd8154b712faf84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d86afaa5675a4776846ffaf4c97e409a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2cab1d494c454a1abfca420484d952f6",
       "IPY_MODEL_9aca2f8e1f6644eebddb205ea4a5e0c5",
       "IPY_MODEL_987333f84cdb4dfca94e41e1b6b2246e"
      ],
      "layout": "IPY_MODEL_309537918947492d8c771b8b20aef21e"
     }
    },
    "dbbc074448f740f99b37e456752a67e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2829b790c46d4e05983d501f910ed7f7",
      "placeholder": "​",
      "style": "IPY_MODEL_28ba10dfff154193a8bfb648e7fca4c3",
      "value": "100%"
     }
    },
    "dd3e462a7cee40f9b6b6a63307c0735b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e203a6f9f2c1430582f060a9ea71c57e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4c9e1a41cbc4b86a249fee581c9175e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d158c3785b5c4b13a9024a0d3e1c0ef2",
      "max": 4846,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd3e462a7cee40f9b6b6a63307c0735b",
      "value": 4846
     }
    },
    "f21445de34624b6e92a86a4fc470c71f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f342d35498a345f1991a5afc0a0edbca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6721fa7ba8742129ad53abffb5a4d2b",
      "max": 4846,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b26d75d84741429fa34441fec197307f",
      "value": 4846
     }
    },
    "f6721fa7ba8742129ad53abffb5a4d2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f843c915c5e042e5ac3f5ab6c45572d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
